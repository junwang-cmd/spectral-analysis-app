# ====================================
# å¯¼å…¥å¿…è¦çš„åº“
# ====================================

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import base64
import traceback
import time
from io import BytesIO

# æœºå™¨å­¦ä¹ ç›¸å…³
from sklearn.model_selection import train_test_split, KFold, LeaveOneOut, cross_val_score
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.decomposition import PCA
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.cross_decomposition import PLSRegression
from sklearn.multioutput import MultiOutputRegressor
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

# ç‰¹å¾é€‰æ‹©ç›¸å…³
from sklearn.feature_selection import (
    VarianceThreshold, SelectKBest, f_regression, mutual_info_regression,
    RFE, SelectFromModel
)

# ä¿¡å·å¤„ç†ç›¸å…³
from scipy.signal import savgol_filter
from scipy import sparse
from scipy.sparse.linalg import spsolve

# è®¾ç½®matplotlibä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# ====================================
# 1. é¡µé¢é…ç½®å’Œæ ·å¼è®¾ç½®
# ====================================

def set_page_style():
    """è®¾ç½®é¡µé¢æ ·å¼"""
    st.markdown("""
    <style>
    .main {
        padding-top: 2rem;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 2px;
    }
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        padding-left: 20px;
        padding-right: 20px;
    }
    .section-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
        padding: 1rem;
        background: linear-gradient(90deg, #f0f8ff 0%, #e6f3ff 100%);
        border-radius: 10px;
        border-left: 5px solid #1f77b4;
    }
    .info-box {
        background-color: #f0f8ff;
        padding: 1rem;
        border-radius: 5px;
        border-left: 4px solid #1f77b4;
        margin: 1rem 0;
    }
    .warning-box {
        background-color: #fff3cd;
        padding: 1rem;
        border-radius: 5px;
        border-left: 4px solid #ffc107;
        margin: 1rem 0;
    }
    .success-box {
        background-color: #d4edda;
        padding: 1rem;
        border-radius: 5px;
        border-left: 4px solid #28a745;
        margin: 1rem 0;
    }
    </style>
    """, unsafe_allow_html=True)

def init_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    if 'data_loaded' not in st.session_state:
        st.session_state.data_loaded = False
    if 'preprocessing_done' not in st.session_state:
        st.session_state.preprocessing_done = False
    if 'feature_selected' not in st.session_state:
        st.session_state.feature_selected = False
    if 'selected_features' not in st.session_state:
        st.session_state.selected_features = None
    if 'feature_selection_method' not in st.session_state:
        st.session_state.feature_selection_method = None
    if 'feature_selector' not in st.session_state:
        st.session_state.feature_selector = None

# ====================================
# 2. åŸºçº¿æ ¡æ­£ç®—æ³•ç±»
# ====================================

class SpectrumBaselineCorrector:
    """å…‰è°±åŸºçº¿æ ¡æ­£ç®—æ³•é›†åˆ"""
    
    @staticmethod
    def airpls(y, lambda_=1e4, porder=1, itermax=15):
        """
        è‡ªé€‚åº”è¿­ä»£åŠ æƒæƒ©ç½šæœ€å°äºŒä¹˜æ³• (Adaptive Iteratively Reweighted Penalized Least Squares)
        """
        m = len(y)
        D = sparse.diags([1, -2, 1], [0, -1, -2], shape=(m, m-2))
        D = lambda_ * D.dot(D.transpose())
        
        w = np.ones(m)
        W = sparse.spdiags(w, 0, m, m)
        
        for i in range(1, itermax+1):
            W.setdiag(w)
            Z = W + D
            z = spsolve(Z, w*y)
            d = y - z
            
            # æ›´æ–°æƒé‡
            dn = d[d < 0]
            m_dn = np.mean(dn) if len(dn) > 0 else 0
            s_dn = np.std(dn) if len(dn) > 0 else 1
            
            wt = 1 / (1 + np.exp(2 * (d - (2*s_dn - m_dn))/s_dn))
            
            if np.linalg.norm(w - wt) / np.linalg.norm(w) < 1e-3:
                break
            w = wt
        
        return z, y - z
    
    @staticmethod
    def asls(y, lam=1e4, p=0.001, niter=10):
        """
        éå¯¹ç§°æœ€å°äºŒä¹˜æ³• (Asymmetric Least Squares)
        """
        L = len(y)
        D = sparse.diags([1, -2, 1], [0, -1, -2], shape=(L, L-2))
        D = lam * D.dot(D.transpose())
        
        w = np.ones(L)
        W = sparse.spdiags(w, 0, L, L)
        
        for i in range(niter):
            W.setdiag(w)
            Z = W + D
            z = spsolve(Z, w*y)
            w = p * (y > z) + (1-p) * (y < z)
        
        return z, y - z
    
    @staticmethod
    def polynomial_baseline(y, degree=2):
        """
        å¤šé¡¹å¼åŸºçº¿æ ¡æ­£
        """
        x = np.arange(len(y))
        coeffs = np.polyfit(x, y, degree)
        baseline = np.polyval(coeffs, x)
        return baseline, y - baseline
    
    @staticmethod
    def modpoly(y, degree=2, repitition=100):
        """
        ä¿®æ­£å¤šé¡¹å¼åŸºçº¿æ ¡æ­£ (Modified Polynomial)
        """
        x = np.arange(len(y))
        baseline = y.copy()
        
        for _ in range(repitition):
            coeffs = np.polyfit(x, baseline, degree)
            fitted = np.polyval(coeffs, x)
            baseline = np.minimum(baseline, fitted)
        
        return baseline, y - baseline
    
    def correct_baseline(self, spectrum, method='airpls', **kwargs):
        """
        ç»Ÿä¸€çš„åŸºçº¿æ ¡æ­£æ¥å£
        
        Parameters:
        -----------
        spectrum : array-like
            è¾“å…¥å…‰è°±æ•°æ®
        method : str
            åŸºçº¿æ ¡æ­£æ–¹æ³• ('airpls', 'asls', 'polynomial', 'modpoly')
        **kwargs : 
            æ–¹æ³•ç‰¹å®šçš„å‚æ•°
        
        Returns:
        --------
        baseline : ndarray
            åŸºçº¿
        corrected : ndarray
            æ ¡æ­£åçš„å…‰è°±
        """
        if method == 'airpls':
            return self.airpls(spectrum, **kwargs)
        elif method == 'asls':
            return self.asls(spectrum, **kwargs)
        elif method == 'polynomial':
            return self.polynomial_baseline(spectrum, **kwargs)
        elif method == 'modpoly':
            return self.modpoly(spectrum, **kwargs)
        else:
            raise ValueError(f"Unknown baseline correction method: {method}")

# ====================================
# 3. ç‰¹å¾é€‰æ‹©åŠŸèƒ½
# ====================================

def perform_feature_selection(X, y, method, **params):
    """
    æ‰§è¡Œç‰¹å¾é€‰æ‹©
    
    Parameters:
    -----------
    X : array-like
        ç‰¹å¾çŸ©é˜µ
    y : array-like
        ç›®æ ‡å˜é‡
    method : str
        ç‰¹å¾é€‰æ‹©æ–¹æ³•
    **params : dict
        æ–¹æ³•å‚æ•°
    
    Returns:
    --------
    selector : object
        ç‰¹å¾é€‰æ‹©å™¨å¯¹è±¡
    X_selected : array-like
        é€‰æ‹©åçš„ç‰¹å¾çŸ©é˜µ
    selected_indices : array-like
        è¢«é€‰æ‹©çš„ç‰¹å¾ç´¢å¼•
    """
    
    if method == "æ–¹å·®é˜ˆå€¼":
        threshold = params.get('variance_threshold', 0.01)
        selector = VarianceThreshold(threshold=threshold)
        X_selected = selector.fit_transform(X)
        selected_indices = selector.get_support(indices=True)
        
    elif method == "å•å˜é‡é€‰æ‹©":
        k = params.get('k_features', 100)
        score_func = params.get('score_func', f_regression)
        selector = SelectKBest(score_func=score_func, k=min(k, X.shape[1]))
        X_selected = selector.fit_transform(X, y)
        selected_indices = selector.get_support(indices=True)
        
    elif method == "é€’å½’ç‰¹å¾æ¶ˆé™¤":
        n_features = params.get('n_features', 50)
        estimator = params.get('estimator', LinearRegression())
        selector = RFE(estimator=estimator, n_features_to_select=min(n_features, X.shape[1]))
        X_selected = selector.fit_transform(X, y)
        selected_indices = selector.get_support(indices=True)
        
    elif method == "åŸºäºæ¨¡å‹é‡è¦æ€§":
        estimator = params.get('estimator', RandomForestRegressor(n_estimators=100, random_state=42))
        threshold = params.get('threshold', 'mean')
        selector = SelectFromModel(estimator=estimator, threshold=threshold)
        X_selected = selector.fit_transform(X, y)
        selected_indices = selector.get_support(indices=True)
        
    elif method == "ç›¸å…³æ€§ç­›é€‰":
        threshold = params.get('corr_threshold', 0.5)
        # è®¡ç®—æ¯ä¸ªç‰¹å¾ä¸ç›®æ ‡å˜é‡çš„ç›¸å…³æ€§
        if y.ndim > 1:
            # å¤šç›®æ ‡æƒ…å†µï¼Œå–å¹³å‡ç›¸å…³æ€§
            correlations = []
            for i in range(X.shape[1]):
                corr_vals = []
                for j in range(y.shape[1]):
                    corr = np.corrcoef(X[:, i], y[:, j])[0, 1]
                    if not np.isnan(corr):
                        corr_vals.append(abs(corr))
                correlations.append(np.mean(corr_vals) if corr_vals else 0)
        else:
            # å•ç›®æ ‡æƒ…å†µ
            correlations = []
            for i in range(X.shape[1]):
                corr = np.corrcoef(X[:, i], y.flatten())[0, 1]
                correlations.append(abs(corr) if not np.isnan(corr) else 0)
        
        correlations = np.array(correlations)
        selected_indices = np.where(correlations >= threshold)[0]
        
        if len(selected_indices) == 0:
            # å¦‚æœæ²¡æœ‰ç‰¹å¾æ»¡è¶³é˜ˆå€¼ï¼Œé€‰æ‹©ç›¸å…³æ€§æœ€é«˜çš„10ä¸ª
            selected_indices = np.argsort(correlations)[-10:]
        
        X_selected = X[:, selected_indices]
        
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„é€‰æ‹©å™¨å¯¹è±¡
        class CorrelationSelector:
            def __init__(self, selected_indices):
                self.selected_indices = selected_indices
            
            def transform(self, X):
                return X[:, self.selected_indices]
            
            def get_support(self, indices=False):
                if indices:
                    return self.selected_indices
                else:
                    support = np.zeros(X.shape[1], dtype=bool)
                    support[self.selected_indices] = True
                    return support
        
        selector = CorrelationSelector(selected_indices)
    
    else:
        raise ValueError(f"Unknown feature selection method: {method}")
    
    return selector, X_selected, selected_indices

# ====================================
# 4. é¡µé¢å‡½æ•°
# ====================================

def show_data_loading_page():
    """æ•°æ®åŠ è½½ä¸æ ‡ç­¾è¾“å…¥é¡µé¢"""
    st.markdown("<h1 class='section-header'>æ•°æ®åŠ è½½ä¸æ ‡ç­¾è¾“å…¥</h1>", unsafe_allow_html=True)
    
    st.markdown("""
    <div class="info-box">
    è¯·ä¸Šä¼ å…‰è°±æ•°æ®æ–‡ä»¶ï¼Œå¹¶è®¾ç½®ç›®æ ‡å˜é‡ï¼ˆæ ‡ç­¾ï¼‰ã€‚æ”¯æŒé€šè¿‡ä¸Šä¼ æ–‡ä»¶æˆ–æ‰‹åŠ¨è¾“å…¥çš„æ–¹å¼è®¾ç½®æ ‡ç­¾ã€‚
    </div>
    """, unsafe_allow_html=True)
    
    # ä¸Šä¼ å…‰è°±æ•°æ®æ–‡ä»¶
    st.subheader("ğŸ“ ä¸Šä¼ å…‰è°±æ•°æ®æ–‡ä»¶")
    uploaded_file = st.file_uploader("é€‰æ‹©æ–‡ä»¶", type=["csv", "xlsx", "xls"])
    
    if uploaded_file is not None:
        try:
            # è¯»å–æ•°æ®
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file, encoding='utf-8')
            else:
                df = pd.read_excel(uploaded_file)
            
            st.success(f"æ•°æ®ä¸Šä¼ æˆåŠŸï¼å…±{df.shape[0]}è¡Œï¼Œ{df.shape[1]}åˆ—")
            
            # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
            st.subheader("æ•°æ®é¢„è§ˆ")
            st.dataframe(df.head(10))
            
            # æ•°æ®æ ¼å¼æ£€æŸ¥å’Œå¤„ç†
            st.subheader("ğŸ” æ•°æ®æ ¼å¼æ£€æŸ¥")
            
            # æ£€æµ‹æ³¢æ•°åˆ—
            potential_wavenumber_cols = []
            non_numeric_cols = []
            
            for col in df.columns:
                try:
                    float(col)
                    potential_wavenumber_cols.append(col)
                except ValueError:
                    non_numeric_cols.append(col)
            
            st.info(f"æ£€æµ‹åˆ° {len(potential_wavenumber_cols)} ä¸ªæ•°å€¼åˆ—ï¼ˆå¯èƒ½ä¸ºæ³¢æ•°ï¼‰")
            st.info(f"æ£€æµ‹åˆ° {len(non_numeric_cols)} ä¸ªéæ•°å€¼åˆ—")
            
            if len(potential_wavenumber_cols) < 10:
                st.error("æ£€æµ‹åˆ°çš„æ³¢æ•°åˆ—æ•°é‡ä¸è¶³ï¼Œè¯·æ£€æŸ¥æ•°æ®æ ¼å¼")
                return
            
            # è®¾ç½®æ•°æ®ç»“æ„
            start_col = st.selectbox(
                "é€‰æ‹©å…‰è°±æ•°æ®èµ·å§‹åˆ—",
                options=range(len(df.columns)),
                index=min(2, len(df.columns)-1),
                format_func=lambda x: f"ç¬¬{x+1}åˆ—: {df.columns[x]}"
            )
            
            # æå–å…‰è°±æ•°æ®
            spectral_columns = df.columns[start_col:]
            try:
                wavenumbers = pd.Series(spectral_columns).astype(float)
                X = df[spectral_columns].values.astype(float)
                
                st.success(f"å…‰è°±æ•°æ®æå–æˆåŠŸï¼æ³¢æ•°èŒƒå›´: {wavenumbers.min():.1f} ~ {wavenumbers.max():.1f} cmâ»Â¹")
                st.info(f"å…‰è°±æ•°æ®å½¢çŠ¶: {X.shape}")
                
                # ä¿å­˜åˆ°session state
                st.session_state.X = X
                st.session_state.wavenumbers = wavenumbers.values
                
                # ä¿å­˜éå…‰è°±åˆ—ç”¨äºæ ‡ç­¾è®¾ç½®
                if start_col > 0:
                    st.session_state.sample_info = df.iloc[:, :start_col]
                else:
                    st.session_state.sample_info = pd.DataFrame()
                
            except Exception as e:
                st.error(f"å…‰è°±æ•°æ®å¤„ç†å¤±è´¥: {e}")
                return
            
            # æ ‡ç­¾è®¾ç½®éƒ¨åˆ†
            st.subheader("ğŸ·ï¸ ç›®æ ‡å˜é‡è®¾ç½®")
            
            label_method = st.radio(
                "é€‰æ‹©æ ‡ç­¾è¾“å…¥æ–¹å¼",
                ["ä¸Šä¼ æ ‡ç­¾æ–‡ä»¶", "æ‰‹åŠ¨è¾“å…¥æ ‡ç­¾", "ä½¿ç”¨æ•°æ®æ–‡ä»¶ä¸­çš„åˆ—"]
            )
            
            if label_method == "ä¸Šä¼ æ ‡ç­¾æ–‡ä»¶":
                label_file = st.file_uploader("ä¸Šä¼ æ ‡ç­¾æ–‡ä»¶", type=["csv", "xlsx", "xls"], key="label_file")
                
                if label_file is not None:
                    try:
                        if label_file.name.endswith('.csv'):
                            label_df = pd.read_csv(label_file)
                        else:
                            label_df = pd.read_excel(label_file)
                        
                        st.write("æ ‡ç­¾æ–‡ä»¶é¢„è§ˆï¼š")
                        st.dataframe(label_df.head())
                        
                        # é€‰æ‹©æ ‡ç­¾åˆ—
                        available_cols = [col for col in label_df.columns if label_df[col].dtype in ['int64', 'float64']]
                        if available_cols:
                            selected_cols = st.multiselect("é€‰æ‹©ç›®æ ‡å˜é‡åˆ—", available_cols)
                            
                            if selected_cols and len(label_df) == len(df):
                                st.session_state.y = label_df[selected_cols].values
                                st.session_state.selected_cols = selected_cols
                                st.session_state.data_loaded = True
                                st.success("æ ‡ç­¾æ•°æ®è®¾ç½®æˆåŠŸï¼")
                            elif len(label_df) != len(df):
                                st.error("æ ‡ç­¾æ–‡ä»¶çš„è¡Œæ•°ä¸å…‰è°±æ•°æ®ä¸åŒ¹é…")
                        else:
                            st.error("æ ‡ç­¾æ–‡ä»¶ä¸­æ²¡æœ‰æ•°å€¼åˆ—")
                            
                    except Exception as e:
                        st.error(f"æ ‡ç­¾æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
            
            elif label_method == "æ‰‹åŠ¨è¾“å…¥æ ‡ç­¾":
                st.write("è¯·ä¸ºæ¯ä¸ªæ ·æœ¬è¾“å…¥æ ‡ç­¾å€¼ï¼š")
                
                # ç›®æ ‡å˜é‡åç§°è®¾ç½®
                target_names = st.text_input("ç›®æ ‡å˜é‡åç§°ï¼ˆå¤šä¸ªç”¨é€—å·åˆ†éš”ï¼‰", value="æµ“åº¦").split(',')
                target_names = [name.strip() for name in target_names if name.strip()]
                
                if target_names:
                    # åˆ›å»ºè¾“å…¥è¡¨æ ¼
                    n_samples = len(df)
                    n_targets = len(target_names)
                    
                    # åˆå§‹åŒ–æ ‡ç­¾æ•°æ®
                    if 'manual_labels' not in st.session_state:
                        st.session_state.manual_labels = np.zeros((n_samples, n_targets))
                    
                    # è°ƒæ•´æ ‡ç­¾æ•°æ®ç»´åº¦
                    if st.session_state.manual_labels.shape != (n_samples, n_targets):
                        st.session_state.manual_labels = np.zeros((n_samples, n_targets))
                    
                    # æ˜¾ç¤ºè¾“å…¥ç•Œé¢
                    st.write(f"è¯·ä¸º {n_samples} ä¸ªæ ·æœ¬è¾“å…¥ {n_targets} ä¸ªç›®æ ‡å˜é‡çš„å€¼ï¼š")
                    
                    # åˆ†é¡µæ˜¾ç¤ºï¼ˆæ¯é¡µ10ä¸ªæ ·æœ¬ï¼‰
                    samples_per_page = 10
                    n_pages = (n_samples + samples_per_page - 1) // samples_per_page
                    
                    if n_pages > 1:
                        page = st.selectbox("é€‰æ‹©é¡µé¢", range(1, n_pages + 1))
                        start_idx = (page - 1) * samples_per_page
                        end_idx = min(start_idx + samples_per_page, n_samples)
                    else:
                        start_idx = 0
                        end_idx = n_samples
                    
                    # åˆ›å»ºè¾“å…¥è¡¨æ ¼
                    for i in range(start_idx, end_idx):
                        cols = st.columns([1] + [2] * n_targets)
                        with cols[0]:
                            st.write(f"æ ·æœ¬ {i+1}")
                        
                        for j, target_name in enumerate(target_names):
                            with cols[j+1]:
                                value = st.number_input(
                                    target_name,
                                    value=float(st.session_state.manual_labels[i, j]),
                                    key=f"label_{i}_{j}",
                                    format="%.4f"
                                )
                                st.session_state.manual_labels[i, j] = value
                    
                    # è®¾ç½®æ ‡ç­¾æŒ‰é’®
                    if st.button("è®¾ç½®æ ‡ç­¾"):
                        st.session_state.y = st.session_state.manual_labels
                        st.session_state.selected_cols = target_names
                        st.session_state.data_loaded = True
                        st.success("æ‰‹åŠ¨æ ‡ç­¾è®¾ç½®æˆåŠŸï¼")
            
            elif label_method == "ä½¿ç”¨æ•°æ®æ–‡ä»¶ä¸­çš„åˆ—":
                if start_col > 0:
                    available_cols = [col for col in df.columns[:start_col] 
                                    if df[col].dtype in ['int64', 'float64']]
                    
                    if available_cols:
                        selected_cols = st.multiselect("é€‰æ‹©ç›®æ ‡å˜é‡åˆ—", available_cols)
                        
                        if selected_cols:
                            if st.button("è®¾ç½®æ ‡ç­¾"):
                                st.session_state.y = df[selected_cols].values
                                st.session_state.selected_cols = selected_cols
                                st.session_state.data_loaded = True
                                st.success("æ ‡ç­¾è®¾ç½®æˆåŠŸï¼")
                    else:
                        st.warning("å…‰è°±æ•°æ®å‰é¢æ²¡æœ‰æ•°å€¼åˆ—å¯ç”¨ä½œæ ‡ç­¾")
                else:
                    st.warning("æ²¡æœ‰å¯ç”¨çš„åˆ—ä½œä¸ºæ ‡ç­¾")
            
            # æ˜¾ç¤ºå½“å‰çŠ¶æ€
            if st.session_state.data_loaded:
                st.subheader("âœ… æ•°æ®åŠ è½½çŠ¶æ€")
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("æ ·æœ¬æ•°é‡", st.session_state.X.shape[0])
                with col2:
                    st.metric("å…‰è°±ç‰¹å¾æ•°", st.session_state.X.shape[1])
                with col3:
                    st.metric("ç›®æ ‡å˜é‡æ•°", len(st.session_state.selected_cols))
                
                st.write(f"**ç›®æ ‡å˜é‡**: {', '.join(st.session_state.selected_cols)}")
                
                # æ˜¾ç¤ºå…‰è°±é¢„è§ˆ
                st.subheader("å…‰è°±æ•°æ®é¢„è§ˆ")
                fig, ax = plt.subplots(figsize=(12, 6))
                n_samples_to_show = min(10, st.session_state.X.shape[0])
                for i in range(n_samples_to_show):
                    ax.plot(st.session_state.wavenumbers, st.session_state.X[i], alpha=0.7)
                ax.set_xlabel('æ³¢æ•° (cmâ»Â¹)')
                ax.set_ylabel('å¼ºåº¦')
                ax.set_title(f'å…‰è°±æ•°æ®é¢„è§ˆï¼ˆå‰{n_samples_to_show}ä¸ªæ ·æœ¬ï¼‰')
                ax.grid(True, alpha=0.3)
                st.pyplot(fig)
                
        except Exception as e:
            st.error(f"æ•°æ®å¤„ç†å‡ºé”™: {e}")
            st.error(traceback.format_exc())
    else:
        st.info("è¯·ä¸Šä¼ å…‰è°±æ•°æ®æ–‡ä»¶")

def show_preprocessing_page():
    """æ•°æ®é¢„å¤„ç†é¡µé¢"""
    st.markdown("<h1 class='section-header'>æ•°æ®é¢„å¤„ç†</h1>", unsafe_allow_html=True)
    
    if not st.session_state.data_loaded:
        st.warning("è¯·å…ˆå®Œæˆæ•°æ®åŠ è½½å’Œæ ‡ç­¾è®¾ç½®")
        return
    
    st.markdown("""
    <div class="info-box">
    å¯¹å…‰è°±æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼ŒåŒ…æ‹¬æ³¢æ•°èŒƒå›´é€‰æ‹©ã€å¹³æ»‘ã€åŸºçº¿æ ¡æ­£ã€å½’ä¸€åŒ–ç­‰æ­¥éª¤ï¼Œä»¥æé«˜æ•°æ®è´¨é‡å’Œæ¨¡å‹æ€§èƒ½ã€‚
    </div>
    """, unsafe_allow_html=True)
    
    X = st.session_state.X
    y = st.session_state.y
    wavenumbers = st.session_state.wavenumbers
    
    # æ˜¾ç¤ºåŸå§‹æ•°æ®ä¿¡æ¯
    st.subheader("ğŸ“Š åŸå§‹æ•°æ®ä¿¡æ¯")
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("æ ·æœ¬æ•°é‡", X.shape[0])
    with col2:
        st.metric("åŸå§‹ç‰¹å¾æ•°", X.shape[1])
    with col3:
        st.metric("æ³¢æ•°èŒƒå›´", f"{wavenumbers.min():.0f}-{wavenumbers.max():.0f}")
    with col4:
        st.metric("ç›®æ ‡å˜é‡æ•°", y.shape[1] if y.ndim > 1 else 1)
    
    # åˆ›å»ºé¢„å¤„ç†å‚æ•°è®¾ç½®åŒºåŸŸ
    st.subheader("âš™ï¸ é¢„å¤„ç†å‚æ•°è®¾ç½®")
    
    # æ³¢æ•°èŒƒå›´é€‰æ‹©
    st.write("**1. æ³¢æ•°èŒƒå›´é€‰æ‹©**")
    col1, col2 = st.columns(2)
    with col1:
        start_wn = st.number_input("èµ·å§‹æ³¢æ•° (cmâ»Â¹)", 
                                 min_value=float(wavenumbers.min()), 
                                 max_value=float(wavenumbers.max()),
                                 value=float(wavenumbers.min()))
    with col2:
        end_wn = st.number_input("ç»“æŸæ³¢æ•° (cmâ»Â¹)", 
                               min_value=float(wavenumbers.min()), 
                               max_value=float(wavenumbers.max()),
                               value=float(wavenumbers.max()))
    
    # å¹³æ»‘å¤„ç†
    st.write("**2. å¹³æ»‘å¤„ç†**")
    apply_smooth = st.checkbox("åº”ç”¨Savitzky-Golayå¹³æ»‘", value=True)
    if apply_smooth:
        col1, col2 = st.columns(2)
        with col1:
            smooth_window = st.slider("çª—å£å¤§å°", 5, 51, 15, step=2)
        with col2:
            smooth_poly = st.slider("å¤šé¡¹å¼é˜¶æ•°", 1, 5, 3)
    
    # åŸºçº¿æ ¡æ­£
    st.write("**3. åŸºçº¿æ ¡æ­£**")
    apply_baseline = st.checkbox("åº”ç”¨åŸºçº¿æ ¡æ­£", value=True)
    if apply_baseline:
        baseline_method = st.selectbox("åŸºçº¿æ ¡æ­£æ–¹æ³•", 
                                     ["airpls", "asls", "polynomial", "modpoly"])
        
        if baseline_method == "airpls":
            col1, col2 = st.columns(2)
            with col1:
                lambda_param = st.selectbox("Î»å‚æ•°", [1e2, 1e3, 1e4, 1e5, 1e6], index=2)
            with col2:
                max_iter = st.slider("æœ€å¤§è¿­ä»£æ¬¡æ•°", 5, 50, 15)
            baseline_params = {'lambda_': lambda_param, 'itermax': max_iter}
            
        elif baseline_method == "asls":
            col1, col2, col3 = st.columns(3)
            with col1:
                lam = st.selectbox("Î»å‚æ•°", [1e2, 1e3, 1e4, 1e5], index=2)
            with col2:
                p = st.selectbox("på‚æ•°", [0.001, 0.01, 0.1], index=0)
            with col3:
                niter = st.slider("è¿­ä»£æ¬¡æ•°", 5, 20, 10)
            baseline_params = {'lam': lam, 'p': p, 'niter': niter}
            
        elif baseline_method == "polynomial":
            degree = st.slider("å¤šé¡¹å¼é˜¶æ•°", 1, 5, 2)
            baseline_params = {'degree': degree}
            
        elif baseline_method == "modpoly":
            col1, col2 = st.columns(2)
            with col1:
                degree = st.slider("å¤šé¡¹å¼é˜¶æ•°", 1, 5, 2)
            with col2:
                repetition = st.slider("é‡å¤æ¬¡æ•°", 10, 200, 100)
            baseline_params = {'degree': degree, 'repitition': repetition}
    
    # å½’ä¸€åŒ–
    st.write("**4. å½’ä¸€åŒ–**")
    apply_normalize = st.checkbox("åº”ç”¨å½’ä¸€åŒ–", value=True)
    if apply_normalize:
        normalize_method = st.selectbox("å½’ä¸€åŒ–æ–¹æ³•", 
                                      ["area", "max", "vector", "minmax"])
    
    # SNV (æ ‡å‡†æ­£æ€å˜é‡å˜æ¢)
    st.write("**5. æ ‡å‡†æ­£æ€å˜é‡å˜æ¢ (SNV)**")
    apply_snv = st.checkbox("åº”ç”¨SNV", value=False)
    
    # é¢„å¤„ç†é¢„è§ˆ
    if st.button("ğŸ” é¢„è§ˆé¢„å¤„ç†æ•ˆæœ"):
        with st.spinner("æ­£åœ¨å¤„ç†æ•°æ®..."):
            try:
                # æ‰§è¡Œé¢„å¤„ç†æµç¨‹ï¼ˆé¢„è§ˆç‰ˆï¼‰
                X_processed, wavenumbers_processed = perform_preprocessing(
                    X, wavenumbers, start_wn, end_wn, apply_smooth, smooth_window, smooth_poly,
                    apply_baseline, baseline_method, baseline_params, apply_normalize, 
                    normalize_method, apply_snv, preview=True
                )
                
                # æ˜¾ç¤ºé¢„å¤„ç†å‰åå¯¹æ¯”
                show_preprocessing_comparison(X, wavenumbers, X_processed, wavenumbers_processed)
                
            except Exception as e:
                st.error(f"é¢„å¤„ç†é¢„è§ˆå¤±è´¥: {e}")
                st.error(traceback.format_exc())
    
    # åº”ç”¨é¢„å¤„ç†
    if st.button("âœ… åº”ç”¨é¢„å¤„ç†è®¾ç½®", type="primary"):
        with st.spinner("æ­£åœ¨è¿›è¡Œæ•°æ®é¢„å¤„ç†..."):
            try:
                # æ‰§è¡Œå®Œæ•´çš„é¢„å¤„ç†æµç¨‹
                X_processed, wavenumbers_processed = perform_preprocessing(
                    X, wavenumbers, start_wn, end_wn, apply_smooth, smooth_window, smooth_poly,
                    apply_baseline, baseline_method, baseline_params, apply_normalize, 
                    normalize_method, apply_snv, preview=False
                )
                
                # ä¿å­˜é¢„å¤„ç†ç»“æœ
                st.session_state.X_preprocessed = X_processed
                st.session_state.wavenumbers_preprocessed = wavenumbers_processed
                st.session_state.preprocessing_done = True
                
                # é‡ç½®ç‰¹å¾é€‰æ‹©çŠ¶æ€
                st.session_state.feature_selected = False
                st.session_state.selected_features = None
                st.session_state.feature_selector = None
                
                # ä¿å­˜é¢„å¤„ç†å‚æ•°
                st.session_state.preprocessing_params = {
                    'start_wavenumber': start_wn,
                    'end_wavenumber': end_wn,
                    'apply_smooth': apply_smooth,
                    'smooth_window': smooth_window if apply_smooth else None,
                    'smooth_poly': smooth_poly if apply_smooth else None,
                    'apply_baseline': apply_baseline,
                    'baseline_method': baseline_method if apply_baseline else None,
                    'baseline_params': baseline_params if apply_baseline else None,
                    'apply_normalize': apply_normalize,
                    'normalize_method': normalize_method if apply_normalize else None,
                    'apply_snv': apply_snv
                }
                
                st.success("ğŸ‰ æ•°æ®é¢„å¤„ç†å®Œæˆï¼å¯ä»¥è¿›è¡Œä¸‹ä¸€æ­¥ç‰¹å¾æå–å’Œå¯è§†åŒ–ã€‚")
                
                # æ˜¾ç¤ºå¤„ç†ç»“æœç»Ÿè®¡
                st.subheader("ğŸ“Š é¢„å¤„ç†ç»“æœç»Ÿè®¡")
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("å¤„ç†åç‰¹å¾æ•°", X_processed.shape[1])
                with col2:
                    st.metric("ç‰¹å¾å‡å°‘", f"{X.shape[1] - X_processed.shape[1]}")
                with col3:
                    st.metric("å¼ºåº¦èŒƒå›´", f"{X_processed.min():.4f} ~ {X_processed.max():.4f}")
                with col4:
                    st.metric("å¼ºåº¦æ ‡å‡†å·®", f"{X_processed.std():.4f}")
                
            except Exception as e:
                st.error(f"æ•°æ®é¢„å¤„ç†å¤±è´¥: {e}")
                st.error(traceback.format_exc())

def perform_preprocessing(X, wavenumbers, start_wn, end_wn, apply_smooth, smooth_window, 
                         smooth_poly, apply_baseline, baseline_method, baseline_params, 
                         apply_normalize, normalize_method, apply_snv, preview=False):
    """æ‰§è¡Œé¢„å¤„ç†æµç¨‹"""
    
    # 1. æ³¢æ•°èŒƒå›´æˆªå–
    start_idx = np.argmin(np.abs(wavenumbers - start_wn))
    end_idx = np.argmin(np.abs(wavenumbers - end_wn)) + 1
    
    wavenumbers_processed = wavenumbers[start_idx:end_idx]
    X_processed = X[:, start_idx:end_idx]
    
    if preview:
        st.write(f"âœ“ æ³¢æ•°æˆªå–: {start_wn} ~ {end_wn} cmâ»Â¹")
    
    # 2. å¹³æ»‘å¤„ç†
    if apply_smooth:
        X_smooth = np.zeros_like(X_processed)
        for i in range(X_processed.shape[0]):
            X_smooth[i] = savgol_filter(X_processed[i], smooth_window, smooth_poly)
        X_processed = X_smooth
        if preview:
            st.write(f"âœ“ Savitzky-Golayå¹³æ»‘: çª—å£={smooth_window}, é˜¶æ•°={smooth_poly}")
    
    # 3. åŸºçº¿æ ¡æ­£
    if apply_baseline:
        corrector = SpectrumBaselineCorrector()
        X_corr = np.zeros_like(X_processed)
        failed_samples = []
        
        for i in range(X_processed.shape[0]):
            try:
                baseline, corrected = corrector.correct_baseline(
                    X_processed[i], baseline_method, **baseline_params)
                X_corr[i] = corrected
            except Exception as e:
                failed_samples.append(i+1)
                X_corr[i] = X_processed[i]
        
        X_processed = X_corr
        if preview and failed_samples:
            st.warning(f"æ ·æœ¬ {failed_samples} åŸºçº¿æ ¡æ­£å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ•°æ®")
        if preview:
            st.write(f"âœ“ åŸºçº¿æ ¡æ­£: {baseline_method.upper()}")
    
    # 4. å½’ä¸€åŒ–
    if apply_normalize:
        X_norm = np.zeros_like(X_processed)
        for i in range(X_processed.shape[0]):
            if normalize_method == 'area':
                total_area = np.trapz(np.abs(X_processed[i]), wavenumbers_processed)
                X_norm[i] = X_processed[i] / (total_area if total_area != 0 else 1e-9)
            elif normalize_method == 'max':
                max_val = np.max(np.abs(X_processed[i]))
                X_norm[i] = X_processed[i] / (max_val if max_val != 0 else 1e-9)
            elif normalize_method == 'vector':
                norm_val = np.linalg.norm(X_processed[i])
                X_norm[i] = X_processed[i] / (norm_val if norm_val != 0 else 1e-9)
            elif normalize_method == 'minmax':
                min_val, max_val = np.min(X_processed[i]), np.max(X_processed[i])
                if max_val - min_val == 0:
                    X_norm[i] = X_processed[i]
                else:
                    X_norm[i] = (X_processed[i] - min_val) / (max_val - min_val)
        X_processed = X_norm
        if preview:
            st.write(f"âœ“ å½’ä¸€åŒ–: {normalize_method}æ–¹æ³•")
    
    # 5. SNVå¤„ç†
    if apply_snv:
        X_final = np.zeros_like(X_processed)
        for i, spectrum in enumerate(X_processed):
            mean_val = np.mean(spectrum)
            std_val = np.std(spectrum)
            if std_val == 0:
                X_final[i] = spectrum
            else:
                X_final[i] = (spectrum - mean_val) / std_val
        X_processed = X_final
        if preview:
            st.write("âœ“ æ ‡å‡†æ­£æ€å˜é‡å˜æ¢(SNV): å·²åº”ç”¨")
    
    return X_processed, wavenumbers_processed

def show_preprocessing_comparison(X_original, wavenumbers_original, X_processed, wavenumbers_processed):
    """æ˜¾ç¤ºé¢„å¤„ç†å‰åå¯¹æ¯”"""
    st.subheader("ğŸ“ˆ é¢„å¤„ç†æ•ˆæœå¯¹æ¯”")
    
    # é€‰æ‹©å‡ ä¸ªæ ·æœ¬è¿›è¡Œå¯¹æ¯”æ˜¾ç¤º
    n_samples_show = min(5, X_original.shape[0])
    sample_indices = np.linspace(0, X_original.shape[0]-1, n_samples_show, dtype=int)
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # åŸå§‹å…‰è°±
    for i in sample_indices:
        ax1.plot(wavenumbers_original, X_original[i], alpha=0.7, label=f'æ ·æœ¬{i+1}')
    ax1.set_title('é¢„å¤„ç†å‰')
    ax1.set_xlabel('æ³¢æ•° (cmâ»Â¹)')
    ax1.set_ylabel('å¼ºåº¦')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # é¢„å¤„ç†å
    for i in sample_indices:
        ax2.plot(wavenumbers_processed, X_processed[i], alpha=0.7, label=f'æ ·æœ¬{i+1}')
    ax2.set_title('é¢„å¤„ç†å')
    ax2.set_xlabel('æ³¢æ•° (cmâ»Â¹)')
    ax2.set_ylabel('å¼ºåº¦')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    st.pyplot(fig)
    
    # æ˜¾ç¤ºå¤„ç†ç»Ÿè®¡ä¿¡æ¯
    st.subheader("ğŸ“Š é¢„å¤„ç†ç»Ÿè®¡ä¿¡æ¯")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("å¤„ç†åç‰¹å¾æ•°", X_processed.shape[1])
    with col2:
        st.metric("ç‰¹å¾å‡å°‘", f"{X_original.shape[1] - X_processed.shape[1]}")
    with col3:
        st.metric("å¼ºåº¦èŒƒå›´", f"{X_processed.min():.4f} ~ {X_processed.max():.4f}")
    with col4:
        st.metric("å¼ºåº¦æ ‡å‡†å·®", f"{X_processed.std():.4f}")

def show_feature_extraction_page():
    """ç‰¹å¾æå–ä¸å¯è§†åŒ–é¡µé¢"""
    st.markdown("<h1 class='section-header'>ç‰¹å¾æå–ä¸å¯è§†åŒ–</h1>", unsafe_allow_html=True)
    
    if not st.session_state.preprocessing_done:
        st.warning("è¯·å…ˆå®Œæˆæ•°æ®é¢„å¤„ç†")
        return
    
    st.markdown("""
    <div class="info-box">
    å¯¹é¢„å¤„ç†åçš„å…‰è°±æ•°æ®è¿›è¡Œæ¢ç´¢æ€§åˆ†æï¼ŒåŒ…æ‹¬å…‰è°±å¯è§†åŒ–ã€ä¸»æˆåˆ†åˆ†æå’Œç›¸å…³æ€§åˆ†æï¼Œä»¥åŠå¯é€‰çš„ç‰¹å¾é€‰æ‹©ã€‚
    </div>
    """, unsafe_allow_html=True)
    
    X = st.session_state.X_preprocessed
    y = st.session_state.y
    wavenumbers = st.session_state.wavenumbers_preprocessed
    target_names = st.session_state.selected_cols
    
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["å…‰è°±å¯è§†åŒ–", "ä¸»æˆåˆ†åˆ†æ", "ç›¸å…³æ€§åˆ†æ", "æ•°æ®ç»Ÿè®¡", "ç‰¹å¾é€‰æ‹©"])
    
    with tab1:
        st.subheader("ğŸŒˆ å…‰è°±æ•°æ®å¯è§†åŒ–")
        
        # å…‰è°±æ˜¾ç¤ºé€‰é¡¹
        col1, col2 = st.columns(2)
        with col1:
            n_spectra = st.slider("æ˜¾ç¤ºå…‰è°±æ•°é‡", 1, min(50, X.shape[0]), min(10, X.shape[0]))
        with col2:
            plot_type = st.selectbox("ç»˜å›¾ç±»å‹", ["çº¿å›¾", "å¡«å……å›¾", "3Då›¾"])
        
        # æ˜¾ç¤ºå…‰è°±
        if plot_type == "çº¿å›¾":
            fig, ax = plt.subplots(figsize=(12, 8))
            sample_indices = np.linspace(0, X.shape[0]-1, n_spectra, dtype=int)
            
            for i, idx in enumerate(sample_indices):
                ax.plot(wavenumbers, X[idx], alpha=0.7, label=f'æ ·æœ¬ {idx+1}')
            
            ax.set_xlabel('æ³¢æ•° (cmâ»Â¹)')
            ax.set_ylabel('å¼ºåº¦')
            ax.set_title('é¢„å¤„ç†åå…‰è°±')
            if n_spectra <= 10:
                ax.legend()
            ax.grid(True, alpha=0.3)
            st.pyplot(fig)
        
        elif plot_type == "å¡«å……å›¾":
            fig, ax = plt.subplots(figsize=(12, 8))
            sample_indices = np.linspace(0, X.shape[0]-1, n_spectra, dtype=int)
            
            for i, idx in enumerate(sample_indices):
                ax.fill_between(wavenumbers, X[idx], alpha=0.3, label=f'æ ·æœ¬ {idx+1}')
            
            ax.set_xlabel('æ³¢æ•° (cmâ»Â¹)')
            ax.set_ylabel('å¼ºåº¦')
            ax.set_title('é¢„å¤„ç†åå…‰è°±ï¼ˆå¡«å……å›¾ï¼‰')
            if n_spectra <= 10:
                ax.legend()
            ax.grid(True, alpha=0.3)
            st.pyplot(fig)
        
        elif plot_type == "3Då›¾":
            from mpl_toolkits.mplot3d import Axes3D
            
            fig = plt.figure(figsize=(12, 8))
            ax = fig.add_subplot(111, projection='3d')
            
            sample_indices = np.linspace(0, X.shape[0]-1, n_spectra, dtype=int)
            
            for i, idx in enumerate(sample_indices):
                ax.plot(wavenumbers, [i]*len(wavenumbers), X[idx], alpha=0.7)
            
            ax.set_xlabel('æ³¢æ•° (cmâ»Â¹)')
            ax.set_ylabel('æ ·æœ¬ç´¢å¼•')
            ax.set_zlabel('å¼ºåº¦')
            ax.set_title('é¢„å¤„ç†åå…‰è°±ï¼ˆ3Då›¾ï¼‰')
            st.pyplot(fig)
        
        # ç»Ÿè®¡å›¾è¡¨
        st.subheader("ğŸ“Š å…‰è°±ç»Ÿè®¡ä¿¡æ¯")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # å¹³å‡å…‰è°±å’Œæ ‡å‡†å·®
            mean_spectrum = np.mean(X, axis=0)
            std_spectrum = np.std(X, axis=0)
            
            fig, ax = plt.subplots(figsize=(10, 6))
            ax.plot(wavenumbers, mean_spectrum, 'b-', linewidth=2, label='å¹³å‡å…‰è°±')
            ax.fill_between(wavenumbers, mean_spectrum - std_spectrum, 
                           mean_spectrum + std_spectrum, alpha=0.3, color='blue', label='Â±1Ïƒ')
            ax.set_xlabel('æ³¢æ•° (cmâ»Â¹)')
            ax.set_ylabel('å¼ºåº¦')
            ax.set_title('å¹³å‡å…‰è°±ä¸æ ‡å‡†å·®')
            ax.legend()
            ax.grid(True, alpha=0.3)
            st.pyplot(fig)
        
        with col2:
            # å…‰è°±å¼ºåº¦çƒ­å›¾
            fig, ax = plt.subplots(figsize=(10, 6))
            
            # é€‰æ‹©éƒ¨åˆ†æ ·æœ¬å’Œæ³¢æ•°ç‚¹è¿›è¡Œæ˜¾ç¤º
            n_samples_heatmap = min(50, X.shape[0])
            n_wavenumbers_heatmap = min(100, X.shape[1])
            
            sample_step = max(1, X.shape[0] // n_samples_heatmap)
            wavenumber_step = max(1, X.shape[1] // n_wavenumbers_heatmap)
            
            X_subset = X[::sample_step, ::wavenumber_step]
            wavenumbers_subset = wavenumbers[::wavenumber_step]
            
            im = ax.imshow(X_subset, aspect='auto', cmap='viridis', interpolation='nearest')
            ax.set_xlabel('æ³¢æ•°ç´¢å¼•')
            ax.set_ylabel('æ ·æœ¬ç´¢å¼•')
            ax.set_title('å…‰è°±å¼ºåº¦çƒ­å›¾')
            
            # è®¾ç½®xè½´æ ‡ç­¾
            if len(wavenumbers_subset) > 10:
                tick_indices = np.linspace(0, len(wavenumbers_subset)-1, 10, dtype=int)
                ax.set_xticks(tick_indices)
                ax.set_xticklabels([f'{wavenumbers_subset[i]:.0f}' for i in tick_indices], rotation=45)
            
            plt.colorbar(im, ax=ax, label='å¼ºåº¦')
            st.pyplot(fig)
    
    with tab2:
        st.subheader("ğŸ” ä¸»æˆåˆ†åˆ†æ (PCA)")
        
        # PCAå‚æ•°è®¾ç½®
        col1, col2 = st.columns(2)
        with col1:
            n_components = st.slider("ä¸»æˆåˆ†æ•°é‡", 2, min(10, X.shape[1], X.shape[0]), 3)
        with col2:
            scale_data = st.checkbox("æ ‡å‡†åŒ–æ•°æ®", value=True)
        
        if st.button("æ‰§è¡ŒPCAåˆ†æ"):
            # æ‰§è¡ŒPCA
            if scale_data:
                scaler = StandardScaler()
                X_scaled = scaler.fit_transform(X)
            else:
                X_scaled = X
            
            pca = PCA(n_components=n_components)
            X_pca = pca.fit_transform(X_scaled)
            
            # ä¿å­˜PCAç»“æœ
            st.session_state.pca_result = {
                'X_pca': X_pca,
                'pca': pca,
                'explained_variance': pca.explained_variance_ratio_
            }
            
            # æ˜¾ç¤ºè§£é‡Šæ–¹å·®
            explained_variance = pca.explained_variance_ratio_
            cumulative_variance = np.cumsum(explained_variance)
            
            col1, col2 = st.columns(2)
            
            with col1:
                # è§£é‡Šæ–¹å·®å›¾
                fig, ax = plt.subplots(figsize=(10, 6))
                bars = ax.bar(range(1, n_components+1), explained_variance * 100)
                ax.set_xlabel('ä¸»æˆåˆ†')
                ax.set_ylabel('è§£é‡Šæ–¹å·®æ¯”ä¾‹ (%)')
                ax.set_title('å„ä¸»æˆåˆ†è§£é‡Šæ–¹å·®')
                ax.grid(True, alpha=0.3)
                
                # æ·»åŠ æ•°å€¼æ ‡ç­¾
                for bar, var in zip(bars, explained_variance):
                    height = bar.get_height()
                    ax.text(bar.get_x() + bar.get_width()/2., height + 0.5,
                           f'{var*100:.1f}%', ha='center', va='bottom')
                
                st.pyplot(fig)
            
            with col2:
                # ç´¯ç§¯è§£é‡Šæ–¹å·®å›¾
                fig, ax = plt.subplots(figsize=(10, 6))
                ax.plot(range(1, n_components+1), cumulative_variance * 100, 'bo-', linewidth=2, markersize=8)
                ax.set_xlabel('ä¸»æˆåˆ†æ•°é‡')
                ax.set_ylabel('ç´¯ç§¯è§£é‡Šæ–¹å·®æ¯”ä¾‹ (%)')
                ax.set_title('ç´¯ç§¯è§£é‡Šæ–¹å·®')
                ax.grid(True, alpha=0.3)
                
                # æ·»åŠ æ•°å€¼æ ‡ç­¾
                for i, cum_var in enumerate(cumulative_variance):
                    ax.text(i+1, cum_var*100 + 1, f'{cum_var*100:.1f}%', 
                           ha='center', va='bottom')
                
                st.pyplot(fig)
        
        # PCAå¾—åˆ†å›¾
        if hasattr(st.session_state, 'pca_result'):
            X_pca = st.session_state.pca_result['X_pca']
            explained_variance = st.session_state.pca_result['explained_variance']
            
            if st.checkbox("æ˜¾ç¤ºPCAå¾—åˆ†å›¾"):
                if len(target_names) == 1:
                    # å•ç›®æ ‡å˜é‡ï¼šæ ¹æ®ç›®æ ‡å€¼ç€è‰²
                    fig, ax = plt.subplots(figsize=(10, 8))
                    scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], c=y.flatten(), 
                                       cmap='viridis', alpha=0.7, s=60)
                    plt.colorbar(scatter, ax=ax, label=target_names[0])
                else:
                    # å¤šç›®æ ‡å˜é‡ï¼šä½¿ç”¨é»˜è®¤é¢œè‰²
                    fig, ax = plt.subplots(figsize=(10, 8))
                    ax.scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.7, s=60)
                
                ax.set_xlabel(f'PC1 ({explained_variance[0]*100:.2f}%)')
                ax.set_ylabel(f'PC2 ({explained_variance[1]*100:.2f}%)')
                ax.set_title('PCAå¾—åˆ†å›¾')
                ax.grid(True, alpha=0.3)
                st.pyplot(fig)
        
        # è½½è·å›¾
        if hasattr(st.session_state, 'pca_result'):
            pca = st.session_state.pca_result['pca']
            
            if st.checkbox("æ˜¾ç¤ºè½½è·å›¾"):
                fig, ax = plt.subplots(figsize=(12, 6))
                
                for i in range(min(3, n_components)):
                    ax.plot(wavenumbers, pca.components_[i], label=f'PC{i+1}')
                
                ax.set_xlabel('æ³¢æ•° (cmâ»Â¹)')
                ax.set_ylabel('è½½è·')
                ax.set_title('ä¸»æˆåˆ†è½½è·å›¾')
                ax.legend()
                ax.grid(True, alpha=0.3)
                st.pyplot(fig)
    
    with tab3:
        st.subheader("ğŸ”— ç›¸å…³æ€§åˆ†æ")
        
        if len(target_names) == 1:
            # å•ç›®æ ‡å˜é‡ï¼šè®¡ç®—æ¯ä¸ªæ³¢æ•°ä¸ç›®æ ‡çš„ç›¸å…³æ€§
            correlations = []
            for i in range(X.shape[1]):
                corr = np.corrcoef(X[:, i], y.flatten())[0, 1]
                correlations.append(corr)
            
            correlations = np.array(correlations)
            
            fig, ax = plt.subplots(figsize=(12, 6))
            ax.plot(wavenumbers, correlations)
            ax.axhline(y=0, color='k', linestyle='--', alpha=0.5)
            ax.set_xlabel('æ³¢æ•° (cmâ»Â¹)')
            ax.set_ylabel(f'ä¸{target_names[0]}çš„ç›¸å…³ç³»æ•°')
            ax.set_title('å…‰è°±-ç›®æ ‡å˜é‡ç›¸å…³æ€§')
            ax.grid(True, alpha=0.3)
            st.pyplot(fig)
            
            # æ‰¾å‡ºæœ€ç›¸å…³çš„æ³¢æ•°
            high_corr_indices = np.argsort(np.abs(correlations))[-10:]
            st.write("**æœ€ç›¸å…³çš„10ä¸ªæ³¢æ•°ï¼š**")
            for idx in reversed(high_corr_indices):
                st.write(f"æ³¢æ•° {wavenumbers[idx]:.2f} cmâ»Â¹: ç›¸å…³ç³»æ•° = {correlations[idx]:.4f}")
        
        else:
            # å¤šç›®æ ‡å˜é‡ï¼šæ˜¾ç¤ºç›®æ ‡å˜é‡é—´çš„ç›¸å…³æ€§
            target_corr = np.corrcoef(y.T)
            
            fig, ax = plt.subplots(figsize=(8, 6))
            im = ax.imshow(target_corr, cmap='RdBu_r', vmin=-1, vmax=1)
            
            # è®¾ç½®åˆ»åº¦æ ‡ç­¾
            ax.set_xticks(range(len(target_names)))
            ax.set_yticks(range(len(target_names)))
            ax.set_xticklabels(target_names, rotation=45)
            ax.set_yticklabels(target_names)
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for i in range(len(target_names)):
                for j in range(len(target_names)):
                    ax.text(j, i, f'{target_corr[i, j]:.3f}', 
                           ha="center", va="center", color="black")
            
            ax.set_title('ç›®æ ‡å˜é‡ç›¸å…³æ€§çŸ©é˜µ')
            plt.colorbar(im)
            st.pyplot(fig)
    
    with tab4:
        st.subheader("ğŸ“ˆ æ•°æ®ç»Ÿè®¡ä¿¡æ¯")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**å…‰è°±æ•°æ®ç»Ÿè®¡ï¼š**")
            st.write(f"æ ·æœ¬æ•°é‡: {X.shape[0]}")
            st.write(f"ç‰¹å¾æ•°é‡: {X.shape[1]}")
            st.write(f"æ³¢æ•°èŒƒå›´: {wavenumbers.min():.2f} ~ {wavenumbers.max():.2f} cmâ»Â¹")
            st.write(f"å…‰è°±å¼ºåº¦èŒƒå›´: {X.min():.4f} ~ {X.max():.4f}")
            st.write(f"å…‰è°±å¼ºåº¦å‡å€¼: {X.mean():.4f}")
            st.write(f"å…‰è°±å¼ºåº¦æ ‡å‡†å·®: {X.std():.4f}")
        
        with col2:
            st.write("**ç›®æ ‡å˜é‡ç»Ÿè®¡ï¼š**")
            for i, target_name in enumerate(target_names):
                if len(target_names) == 1:
                    target_values = y.flatten()
                else:
                    target_values = y[:, i]
                
                st.write(f"**{target_name}:**")
                st.write(f"  èŒƒå›´: {target_values.min():.4f} ~ {target_values.max():.4f}")
                st.write(f"  å‡å€¼: {target_values.mean():.4f}")
                st.write(f"  æ ‡å‡†å·®: {target_values.std():.4f}")
        
        # å…‰è°±å¼ºåº¦åˆ†å¸ƒ
        st.write("**å…‰è°±å¼ºåº¦åˆ†å¸ƒï¼š**")
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.hist(X.flatten(), bins=50, alpha=0.7, density=True)
        ax.set_xlabel('å¼ºåº¦å€¼')
        ax.set_ylabel('å¯†åº¦')
        ax.set_title('å…‰è°±å¼ºåº¦åˆ†å¸ƒç›´æ–¹å›¾')
        ax.grid(True, alpha=0.3)
        st.pyplot(fig)
    
    with tab5:
        st.subheader("ğŸ¯ ç‰¹å¾é€‰æ‹©")
        st.markdown("é€‰æ‹©å¯¹ç›®æ ‡å˜é‡æœ€é‡è¦çš„ç‰¹å¾ï¼Œå‡å°‘æ•°æ®ç»´åº¦å¹¶æé«˜æ¨¡å‹æ€§èƒ½ã€‚")

        feature_method = st.selectbox(
            "é€‰æ‹©ç‰¹å¾é€‰æ‹©æ–¹æ³•",
            ["ä¸è¿›è¡Œç‰¹å¾é€‰æ‹©", "æ–¹å·®é˜ˆå€¼", "å•å˜é‡é€‰æ‹©", "é€’å½’ç‰¹å¾æ¶ˆé™¤", "åŸºäºæ¨¡å‹é‡è¦æ€§", "ç›¸å…³æ€§ç­›é€‰"]
        )

        if feature_method == "ä¸è¿›è¡Œç‰¹å¾é€‰æ‹©":
            if st.button("ç¡®è®¤ä¸è¿›è¡Œç‰¹å¾é€‰æ‹©"):
                # ä½¿ç”¨å…¨éƒ¨é¢„å¤„ç†åçš„ç‰¹å¾
                st.session_state.X_final = X
                st.session_state.wavenumbers_final = wavenumbers
                st.session_state.feature_selected = True
                st.session_state.selected_features = None
                st.session_state.feature_selector = None
                st.session_state.feature_selection_method = "ä¸è¿›è¡Œç‰¹å¾é€‰æ‹©"
                
                st.success("âœ… å·²ç¡®è®¤ä½¿ç”¨å…¨éƒ¨é¢„å¤„ç†åçš„ç‰¹å¾è¿›è¡Œå»ºæ¨¡")
                st.info(f"æœ€ç»ˆç‰¹å¾æ•°é‡: {X.shape[1]}")

        else:
            # ç‰¹å¾é€‰æ‹©å‚æ•°è®¾ç½®
            params = {}
            
            if feature_method == "æ–¹å·®é˜ˆå€¼":
                variance_threshold = st.slider("æ–¹å·®é˜ˆå€¼", min_value=0.0, max_value=1.0, value=0.01, step=0.01)
                params['variance_threshold'] = variance_threshold
                
            elif feature_method == "å•å˜é‡é€‰æ‹©":
                k_features = st.slider("é€‰æ‹©ç‰¹å¾æ•°é‡", min_value=10, max_value=min(500, X.shape[1]), value=100)
                score_func_name = st.selectbox("è¯„åˆ†å‡½æ•°", ["f_regression", "mutual_info_regression"])
                params['k_features'] = k_features
                params['score_func'] = f_regression if score_func_name == "f_regression" else mutual_info_regression
                
            elif feature_method == "é€’å½’ç‰¹å¾æ¶ˆé™¤":
                n_features = st.slider("ç›®æ ‡ç‰¹å¾æ•°é‡", min_value=10, max_value=min(200, X.shape[1]), value=50)
                estimator_name = st.selectbox("åŸºç¡€ä¼°è®¡å™¨", ["çº¿æ€§å›å½’", "éšæœºæ£®æ—"])
                params['n_features'] = n_features
                if estimator_name == "çº¿æ€§å›å½’":
                    params['estimator'] = LinearRegression()
                else:
                    params['estimator'] = RandomForestRegressor(n_estimators=50, random_state=42)
                    
            elif feature_method == "åŸºäºæ¨¡å‹é‡è¦æ€§":
                estimator_name = st.selectbox("åŸºç¡€ä¼°è®¡å™¨", ["éšæœºæ£®æ—", "æ¢¯åº¦æå‡"])
                threshold_type = st.selectbox("é˜ˆå€¼ç±»å‹", ["mean", "median"])
                
                if estimator_name == "éšæœºæ£®æ—":
                    params['estimator'] = RandomForestRegressor(n_estimators=100, random_state=42)
                else:
                    params['estimator'] = GradientBoostingRegressor(n_estimators=100, random_state=42)
                params['threshold'] = threshold_type
                
            elif feature_method == "ç›¸å…³æ€§ç­›é€‰":
                corr_threshold = st.slider("ç›¸å…³æ€§é˜ˆå€¼", min_value=0.1, max_value=0.9, value=0.5, step=0.1)
                params['corr_threshold'] = corr_threshold

            if st.button("æ‰§è¡Œç‰¹å¾é€‰æ‹©"):
                with st.spinner("æ­£åœ¨æ‰§è¡Œç‰¹å¾é€‰æ‹©..."):
                    try:
                        # æ‰§è¡Œç‰¹å¾é€‰æ‹©
                        selector, X_selected, selected_indices = perform_feature_selection(
                            X, y, feature_method, **params
                        )
                        
                        # ä¿å­˜ç‰¹å¾é€‰æ‹©ç»“æœ
                        st.session_state.X_final = X_selected
                        st.session_state.wavenumbers_final = wavenumbers[selected_indices]
                        st.session_state.feature_selected = True
                        st.session_state.selected_features = selected_indices
                        st.session_state.feature_selector = selector
                        st.session_state.feature_selection_method = feature_method
                        
                        st.success("âœ… ç‰¹å¾é€‰æ‹©å®Œæˆï¼")
                        
                        # æ˜¾ç¤ºé€‰æ‹©ç»“æœ
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("åŸå§‹ç‰¹å¾æ•°", X.shape[1])
                        with col2:
                            st.metric("é€‰æ‹©ç‰¹å¾æ•°", X_selected.shape[1])
                        with col3:
                            st.metric("ç‰¹å¾å‡å°‘", X.shape[1] - X_selected.shape[1])
                        
                        # å¯è§†åŒ–ç‰¹å¾é€‰æ‹©ç»“æœ
                        st.subheader("ğŸ“Š ç‰¹å¾é€‰æ‹©ç»“æœå¯è§†åŒ–")
                        
                        # ç‰¹å¾é‡è¦æ€§/ç›¸å…³æ€§å›¾
                        if feature_method == "å•å˜é‡é€‰æ‹©":
                            # æ˜¾ç¤ºè¯„åˆ†
                            scores = selector.scores_[selected_indices]
                            fig, ax = plt.subplots(figsize=(12, 6))
                            ax.plot(wavenumbers[selected_indices], scores, 'bo-', alpha=0.7)
                            ax.set_xlabel('æ³¢æ•° (cmâ»Â¹)')
                            ax.set_ylabel('ç‰¹å¾è¯„åˆ†')
                            ax.set_title('é€‰æ‹©ç‰¹å¾çš„è¯„åˆ†åˆ†å¸ƒ')
                            ax.grid(True, alpha=0.3)
                            st.pyplot(fig)
                            
                        elif feature_method == "åŸºäºæ¨¡å‹é‡è¦æ€§":
                            # æ˜¾ç¤ºç‰¹å¾é‡è¦æ€§
                            importances = selector.estimator_.feature_importances_[selected_indices]
                            fig, ax = plt.subplots(figsize=(12, 6))
                            ax.plot(wavenumbers[selected_indices], importances, 'ro-', alpha=0.7)
                            ax.set_xlabel('æ³¢æ•° (cmâ»Â¹)')
                            ax.set_ylabel('ç‰¹å¾é‡è¦æ€§')
                            ax.set_title('é€‰æ‹©ç‰¹å¾çš„é‡è¦æ€§åˆ†å¸ƒ')
                            ax.grid(True, alpha=0.3)
                            st.pyplot(fig)
                        
                        # æ˜¾ç¤ºé€‰æ‹©çš„ç‰¹å¾ä½ç½®
                        fig, ax = plt.subplots(figsize=(12, 6))
                        
                        # ç»˜åˆ¶å¹³å‡å…‰è°±
                        mean_spectrum = np.mean(X, axis=0)
                        ax.plot(wavenumbers, mean_spectrum, 'b-', alpha=0.5, label='å¹³å‡å…‰è°±')
                        
                        # æ ‡è®°é€‰æ‹©çš„ç‰¹å¾
                        for idx in selected_indices:
                            ax.axvline(x=wavenumbers[idx], color='red', alpha=0.3)
                        
                        ax.set_xlabel('æ³¢æ•° (cmâ»Â¹)')
                        ax.set_ylabel('å¼ºåº¦')
                        ax.set_title('é€‰æ‹©çš„ç‰¹å¾åœ¨å…‰è°±ä¸­çš„ä½ç½®ï¼ˆçº¢è‰²ç«–çº¿ï¼‰')
                        ax.legend()
                        ax.grid(True, alpha=0.3)
                        st.pyplot(fig)
                        
                        # æ˜¾ç¤ºé€‰æ‹©ç‰¹å¾çš„ç»Ÿè®¡ä¿¡æ¯
                        st.subheader("ğŸ“ˆ é€‰æ‹©ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯")
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.write("**é€‰æ‹©çš„æ³¢æ•°èŒƒå›´ï¼š**")
                            selected_wavenumbers = wavenumbers[selected_indices]
                            st.write(f"æœ€å°æ³¢æ•°: {selected_wavenumbers.min():.2f} cmâ»Â¹")
                            st.write(f"æœ€å¤§æ³¢æ•°: {selected_wavenumbers.max():.2f} cmâ»Â¹")
                            st.write(f"æ³¢æ•°è·¨åº¦: {selected_wavenumbers.max() - selected_wavenumbers.min():.2f} cmâ»Â¹")
                        
                        with col2:
                            st.write("**ç‰¹å¾é€‰æ‹©ç»Ÿè®¡ï¼š**")
                            st.write(f"é€‰æ‹©ç‡: {len(selected_indices)/X.shape[1]*100:.1f}%")
                            st.write(f"æ•°æ®å‹ç¼©æ¯”: {X_selected.shape[1]/X.shape[1]*100:.1f}%")
                            
                            # è®¡ç®—ç‰¹å¾åˆ†å¸ƒ
                            total_range = wavenumbers.max() - wavenumbers.min()
                            selected_range = selected_wavenumbers.max() - selected_wavenumbers.min()
                            st.write(f"æ³¢æ•°è¦†ç›–ç‡: {selected_range/total_range*100:.1f}%")
                        
                    except Exception as e:
                        st.error(f"ç‰¹å¾é€‰æ‹©å¤±è´¥: {e}")
                        st.error(traceback.format_exc())

        # æ˜¾ç¤ºå½“å‰ç‰¹å¾é€‰æ‹©çŠ¶æ€
        if st.session_state.feature_selected:
            st.subheader("âœ… å½“å‰ç‰¹å¾é€‰æ‹©çŠ¶æ€")
            
            method = st.session_state.feature_selection_method
            if method == "ä¸è¿›è¡Œç‰¹å¾é€‰æ‹©":
                st.info("å·²é€‰æ‹©ä½¿ç”¨å…¨éƒ¨é¢„å¤„ç†åçš„ç‰¹å¾")
                st.write(f"æœ€ç»ˆç‰¹å¾æ•°é‡: {st.session_state.X_final.shape[1]}")
            else:
                st.success(f"å·²å®Œæˆç‰¹å¾é€‰æ‹©ï¼Œä½¿ç”¨æ–¹æ³•: {method}")
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("æœ€ç»ˆç‰¹å¾æ•°", st.session_state.X_final.shape[1])
                with col2:
                    st.metric("åŸå§‹ç‰¹å¾æ•°", X.shape[1])
                with col3:
                    reduction = X.shape[1] - st.session_state.X_final.shape[1]
                    st.metric("ç‰¹å¾å‡å°‘", reduction)

def show_data_split_page():
    """æ•°æ®é›†åˆ’åˆ†é¡µé¢"""
    st.markdown("<h1 class='section-header'>æ•°æ®é›†åˆ’åˆ†</h1>", unsafe_allow_html=True)
    
    if not st.session_state.preprocessing_done:
        st.warning("è¯·å…ˆå®Œæˆæ•°æ®é¢„å¤„ç†")
        return
    
    st.markdown("""
    <div class="info-box">
    å°†é¢„å¤„ç†åçš„æ•°æ®åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œæ”¯æŒéšæœºåˆ’åˆ†ã€KæŠ˜äº¤å‰éªŒè¯å’Œç•™ä¸€æ³•ã€‚
    </div>
    """, unsafe_allow_html=True)
    
    # ç¡®å®šä½¿ç”¨çš„æ•°æ®ï¼ˆç‰¹å¾é€‰æ‹©åçš„æˆ–é¢„å¤„ç†åçš„ï¼‰
    if st.session_state.feature_selected:
        X = st.session_state.X_final
        wavenumbers = st.session_state.wavenumbers_final
        st.info(f"âœ… ä½¿ç”¨ç‰¹å¾é€‰æ‹©åçš„æ•°æ®ï¼Œç‰¹å¾æ•°é‡: {X.shape[1]}")
    else:
        X = st.session_state.X_preprocessed
        wavenumbers = st.session_state.wavenumbers_preprocessed
        st.info(f"â„¹ï¸ ä½¿ç”¨é¢„å¤„ç†åçš„å…¨éƒ¨ç‰¹å¾ï¼Œç‰¹å¾æ•°é‡: {X.shape[1]}")
    
    y = st.session_state.y
    
    # åˆ’åˆ†æ–¹æ³•é€‰æ‹©
    st.subheader("ğŸ“Š æ•°æ®åˆ’åˆ†æ–¹æ³•")
    split_method = st.radio(
        "é€‰æ‹©æ•°æ®åˆ’åˆ†æ–¹æ³•",
        ["éšæœºåˆ’åˆ†", "KFoldäº¤å‰éªŒè¯", "ç•™ä¸€æ³•(LOOCV)"]
    )
    
    if split_method == "éšæœºåˆ’åˆ†":
        st.subheader("éšæœºåˆ’åˆ†å‚æ•°è®¾ç½®")
        test_size = st.slider("æµ‹è¯•é›†æ¯”ä¾‹", 0.1, 0.5, 0.2, 0.05)
        random_state = st.number_input("éšæœºç§å­", value=42, min_value=0)
        
        if st.button("æ‰§è¡Œæ•°æ®åˆ’åˆ†"):
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=random_state, stratify=None
            )
            
            # ä¿å­˜åˆ’åˆ†ç»“æœ
            st.session_state.X_train = X_train
            st.session_state.X_test = X_test
            st.session_state.y_train = y_train
            st.session_state.y_test = y_test
            st.session_state.split_method = split_method
            
            st.success("âœ… æ•°æ®åˆ’åˆ†å®Œæˆï¼")
            
            # æ˜¾ç¤ºåˆ’åˆ†ç»“æœ
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("è®­ç»ƒé›†æ ·æœ¬æ•°", X_train.shape[0])
            with col2:
                st.metric("æµ‹è¯•é›†æ ·æœ¬æ•°", X_test.shape[0])
            with col3:
                st.metric("è®­ç»ƒé›†æ¯”ä¾‹", f"{(1-test_size)*100:.1f}%")
            with col4:
                st.metric("æµ‹è¯•é›†æ¯”ä¾‹", f"{test_size*100:.1f}%")
    
    elif split_method == "KFoldäº¤å‰éªŒè¯":
        st.subheader("KæŠ˜äº¤å‰éªŒè¯å‚æ•°è®¾ç½®")
        cv_splits = st.slider("æŠ˜æ•°(K)", 3, 10, 5)
        random_state = st.number_input("éšæœºç§å­", value=42, min_value=0)
        
        if st.button("è®¾ç½®äº¤å‰éªŒè¯"):
            # ä¿å­˜è®¾ç½®
            st.session_state.X_train = X
            st.session_state.X_test = None
            st.session_state.y_train = y
            st.session_state.y_test = None
            st.session_state.split_method = split_method
            st.session_state.cv_splits = cv_splits
            st.session_state.random_state = random_state
            
            st.success("âœ… äº¤å‰éªŒè¯è®¾ç½®å®Œæˆï¼")
            st.info(f"å°†ä½¿ç”¨ {cv_splits} æŠ˜äº¤å‰éªŒè¯è¿›è¡Œæ¨¡å‹è¯„ä¼°")
    
    elif split_method == "ç•™ä¸€æ³•(LOOCV)":
        st.subheader("ç•™ä¸€æ³•äº¤å‰éªŒè¯")
        st.info("ç•™ä¸€æ³•å°†ä½¿ç”¨ N-1 ä¸ªæ ·æœ¬è®­ç»ƒï¼Œ1ä¸ªæ ·æœ¬æµ‹è¯•ï¼Œé‡å¤Næ¬¡")
        
        if X.shape[0] > 100:
            st.warning("âš ï¸ æ ·æœ¬æ•°é‡è¾ƒå¤šï¼Œç•™ä¸€æ³•å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´")
        
        if st.button("è®¾ç½®ç•™ä¸€æ³•éªŒè¯"):
            # ä¿å­˜è®¾ç½®
            st.session_state.X_train = X
            st.session_state.X_test = None
            st.session_state.y_train = y
            st.session_state.y_test = None
            st.session_state.split_method = split_method
            
            st.success("âœ… ç•™ä¸€æ³•è®¾ç½®å®Œæˆï¼")
            st.info(f"å°†ä½¿ç”¨ç•™ä¸€æ³•å¯¹ {X.shape[0]} ä¸ªæ ·æœ¬è¿›è¡Œäº¤å‰éªŒè¯")
    
    # æ˜¾ç¤ºå½“å‰æ•°æ®é›†çŠ¶æ€
    if hasattr(st.session_state, 'split_method'):
        st.subheader("ğŸ“ˆ å½“å‰æ•°æ®é›†çŠ¶æ€")
        
        if st.session_state.split_method == "éšæœºåˆ’åˆ†":
            if hasattr(st.session_state, 'X_train'):
                col1, col2 = st.columns(2)
                
                with col1:
                    st.write("**è®­ç»ƒé›†ä¿¡æ¯ï¼š**")
                    st.write(f"æ ·æœ¬æ•°: {st.session_state.X_train.shape[0]}")
                    st.write(f"ç‰¹å¾æ•°: {st.session_state.X_train.shape[1]}")
                    
                with col2:
                    st.write("**æµ‹è¯•é›†ä¿¡æ¯ï¼š**")
                    st.write(f"æ ·æœ¬æ•°: {st.session_state.X_test.shape[0]}")
                    st.write(f"ç‰¹å¾æ•°: {st.session_state.X_test.shape[1]}")
                
                # æ˜¾ç¤ºç›®æ ‡å˜é‡åˆ†å¸ƒå¯¹æ¯”
                if len(st.session_state.selected_cols) == 1:
                    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
                    
                    # è®­ç»ƒé›†åˆ†å¸ƒ
                    ax1.hist(st.session_state.y_train.flatten(), bins=20, alpha=0.7, color='blue')
                    ax1.set_title('è®­ç»ƒé›†ç›®æ ‡å˜é‡åˆ†å¸ƒ')
                    ax1.set_xlabel(st.session_state.selected_cols[0])
                    ax1.set_ylabel('é¢‘æ•°')
                    ax1.grid(True, alpha=0.3)
                    
                    # æµ‹è¯•é›†åˆ†å¸ƒ
                    ax2.hist(st.session_state.y_test.flatten(), bins=20, alpha=0.7, color='orange')
                    ax2.set_title('æµ‹è¯•é›†ç›®æ ‡å˜é‡åˆ†å¸ƒ')
                    ax2.set_xlabel(st.session_state.selected_cols[0])
                    ax2.set_ylabel('é¢‘æ•°')
                    ax2.grid(True, alpha=0.3)
                    
                    plt.tight_layout()
                    st.pyplot(fig)
        
        else:
            st.info(f"å·²è®¾ç½® {st.session_state.split_method}ï¼Œå°†åœ¨æ¨¡å‹è®­ç»ƒæ—¶ä½¿ç”¨")

def show_model_training_page():
    """æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°é¡µé¢"""
    st.markdown("<h1 class='section-header'>æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°</h1>", unsafe_allow_html=True)
    
    if not hasattr(st.session_state, 'split_method'):
        st.warning("è¯·å…ˆå®Œæˆæ•°æ®é›†åˆ’åˆ†")
        return
    
    st.markdown("""
    <div class="info-box">
    é€‰æ‹©æœºå™¨å­¦ä¹ ç®—æ³•è¿›è¡Œæ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ï¼Œæ”¯æŒå¤šç§å›å½’ç®—æ³•å’Œå‚æ•°è°ƒä¼˜ã€‚
    </div>
    """, unsafe_allow_html=True)
    
    # æ˜¾ç¤ºå½“å‰ä½¿ç”¨çš„æ•°æ®ä¿¡æ¯
    if st.session_state.feature_selected:
        st.info(f"âœ… ä½¿ç”¨ç‰¹å¾é€‰æ‹©åçš„æ•°æ®è¿›è¡Œå»ºæ¨¡ - ç‰¹å¾æ•°é‡: {st.session_state.X_final.shape[1]}")
        if st.session_state.feature_selection_method != "ä¸è¿›è¡Œç‰¹å¾é€‰æ‹©":
            st.info(f"ç‰¹å¾é€‰æ‹©æ–¹æ³•: {st.session_state.feature_selection_method}")
    else:
        st.info(f"â„¹ï¸ ä½¿ç”¨é¢„å¤„ç†åçš„å…¨éƒ¨ç‰¹å¾è¿›è¡Œå»ºæ¨¡ - ç‰¹å¾æ•°é‡: {st.session_state.X_preprocessed.shape[1]}")
    
    # å¯ç”¨æ¨¡å‹
    available_models = {
        'linear': 'çº¿æ€§å›å½’',
        'ridge': 'å²­å›å½’',
        'lasso': 'Lassoå›å½’',
        'svr': 'æ”¯æŒå‘é‡å›å½’',
        'rf': 'éšæœºæ£®æ—',
        'gbr': 'æ¢¯åº¦æå‡å›å½’',
        'mlp': 'å¤šå±‚æ„ŸçŸ¥æœº',
        'pls': 'åæœ€å°äºŒä¹˜å›å½’'
    }
    
    try:
        import xgboost as xgb
        available_models['xgb'] = 'XGBoost'
    except ImportError:
        pass
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºå¤šè¾“å‡ºé—®é¢˜
    is_multioutput = len(st.session_state.selected_cols) > 1
    
    # æ¨¡å‹é€‰æ‹©
    st.subheader("ğŸ¤– æ¨¡å‹é€‰æ‹©ä¸å‚æ•°è®¾ç½®")
    selected_models = st.multiselect("é€‰æ‹©è¦è®­ç»ƒçš„æ¨¡å‹", list(available_models.keys()), 
                                   format_func=lambda x: available_models[x])
    
    if not selected_models:
        st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ¨¡å‹")
        return
    
    # æ¨¡å‹å‚æ•°è®¾ç½®
    model_params = {}
    
    for i, model_name in enumerate(selected_models):
        st.subheader(f"âš™ï¸ {available_models[model_name]} å‚æ•°è®¾ç½®")
        
        if model_name == 'linear':
            # çº¿æ€§å›å½’å‚æ•°
            fit_intercept = st.checkbox("æ‹Ÿåˆæˆªè·", value=True, key=f"linear_intercept_{i}")
            use_scaler = st.checkbox("ä½¿ç”¨æ ‡å‡†åŒ–", value=True, key=f"linear_scaler_{i}")
            
            model_params['linear'] = {
                'fit_intercept': fit_intercept,
                'use_scaler': use_scaler
            }
        
        elif model_name == 'ridge':
            # å²­å›å½’å‚æ•°
            col1, col2 = st.columns(2)
            with col1:
                alpha = st.selectbox("æ­£åˆ™åŒ–å‚æ•°Î±", [0.01, 0.1, 1.0, 10.0, 100.0], 
                                   index=2, key=f"ridge_alpha_{i}")
                fit_intercept = st.checkbox("æ‹Ÿåˆæˆªè·", value=True, key=f"ridge_intercept_{i}")
            with col2:
                solver = st.selectbox("æ±‚è§£å™¨", ['auto', 'svd', 'cholesky', 'lsqr'], 
                                    index=0, key=f"ridge_solver_{i}")
                use_scaler = st.checkbox("ä½¿ç”¨æ ‡å‡†åŒ–", value=True, key=f"ridge_scaler_{i}")
            
            model_params['ridge'] = {
                'alpha': alpha,
                'fit_intercept': fit_intercept,
                'solver': solver,
                'use_scaler': use_scaler
            }
        
        elif model_name == 'lasso':
            # Lassoå›å½’å‚æ•°
            col1, col2 = st.columns(2)
            with col1:
                alpha = st.selectbox("æ­£åˆ™åŒ–å‚æ•°Î±", [0.01, 0.1, 1.0, 10.0], 
                                   index=1, key=f"lasso_alpha_{i}")
                fit_intercept = st.checkbox("æ‹Ÿåˆæˆªè·", value=True, key=f"lasso_intercept_{i}")
            with col2:
                max_iter = st.slider("æœ€å¤§è¿­ä»£æ¬¡æ•°", 100, 2000, 1000, key=f"lasso_iter_{i}")
                use_scaler = st.checkbox("ä½¿ç”¨æ ‡å‡†åŒ–", value=True, key=f"lasso_scaler_{i}")
            
            model_params['lasso'] = {
                'alpha': alpha,
                'fit_intercept': fit_intercept,
                'max_iter': max_iter,
                'use_scaler': use_scaler
            }
        
        elif model_name == 'svr':
            # SVRå‚æ•°
            col1, col2 = st.columns(2)
            with col1:
                kernel = st.selectbox("æ ¸å‡½æ•°", ['rbf', 'linear', 'poly'], 
                                    index=0, key=f"svr_kernel_{i}")
                C = st.selectbox("æƒ©ç½šå‚æ•°C", [0.1, 1.0, 10.0, 100.0], 
                               index=1, key=f"svr_c_{i}")
            with col2:
                gamma = st.selectbox("æ ¸å‚æ•°Î³", ['scale', 'auto'], 
                                   index=0, key=f"svr_gamma_{i}")
                epsilon = st.selectbox("Îµå‚æ•°", [0.01, 0.1, 0.2], 
                                     index=1, key=f"svr_epsilon_{i}")
            
            model_params['svr'] = {
                'kernel': kernel,
                'C': C,
                'gamma': gamma,
                'epsilon': epsilon
            }
        
        elif model_name == 'rf':
            # éšæœºæ£®æ—å‚æ•°
            col1, col2 = st.columns(2)
            with col1:
                n_estimators = st.slider("æ ‘çš„æ•°é‡", 50, 500, 100, key=f"rf_trees_{i}")
                max_depth = st.selectbox("æœ€å¤§æ·±åº¦", [None, 5, 10, 15, 20], 
                                       index=0, key=f"rf_depth_{i}")
            with col2:
                min_samples_split = st.slider("åˆ†è£‚æœ€å°æ ·æœ¬æ•°", 2, 10, 2, key=f"rf_split_{i}")
                min_samples_leaf = st.slider("å¶èŠ‚ç‚¹æœ€å°æ ·æœ¬æ•°", 1, 5, 1, key=f"rf_leaf_{i}")
            
            random_state = st.number_input("éšæœºç§å­", value=42, key=f"rf_seed_{i}")
            
            model_params['rf'] = {
                'n_estimators': n_estimators,
                'max_depth': max_depth,
                'min_samples_split': min_samples_split,
                'min_samples_leaf': min_samples_leaf,
                'random_state': random_state
            }
        
        elif model_name == 'gbr':
            # æ¢¯åº¦æå‡å‚æ•°
            col1, col2 = st.columns(2)
            with col1:
                n_estimators = st.slider("æå‡é˜¶æ®µæ•°", 50, 500, 100, key=f"gbr_stages_{i}")
                learning_rate = st.selectbox("å­¦ä¹ ç‡", [0.01, 0.05, 0.1, 0.2], 
                                           index=2, key=f"gbr_lr_{i}")
            with col2:
                max_depth = st.slider("æœ€å¤§æ·±åº¦", 2, 10, 3, key=f"gbr_depth_{i}")
                subsample = st.slider("å­é‡‡æ ·æ¯”ä¾‹", 0.5, 1.0, 1.0, step=0.1, key=f"gbr_subsample_{i}")
            
            random_state = st.number_input("éšæœºç§å­", value=42, key=f"gbr_seed_{i}")
            
            model_params['gbr'] = {
                'n_estimators': n_estimators,
                'learning_rate': learning_rate,
                'max_depth': max_depth,
                'subsample': subsample,
                'random_state': random_state
            }
        
        elif model_name == 'pls':
            # PLSå‚æ•°
            n_components = st.slider("ä¸»æˆåˆ†æ•°é‡", 1, min(20, st.session_state.X_train.shape[1]), 
                                   5, key=f"pls_components_{i}")
            scale = st.checkbox("æ ‡å‡†åŒ–", value=True, key=f"pls_scale_{i}")
            
            model_params['pls'] = {
                'n_components': n_components,
                'scale': scale
            }
        
        elif model_name == 'mlp':
            # MLPå‚æ•°
            col1, col2 = st.columns(2)
            with col1:
                layer_option = st.selectbox("éšè—å±‚ç»“æ„", ["ä¸€å±‚", "ä¸¤å±‚", "ä¸‰å±‚"], 
                                          index=1, key=f"mlp_layers_{i}")
                
                if layer_option == "ä¸€å±‚":
                    layer1_size = st.slider("éšè—å±‚ç¥ç»å…ƒæ•°", 10, 200, 50, key=f"mlp_l1_{i}")
                    hidden_layer_sizes = (layer1_size,)
                elif layer_option == "ä¸¤å±‚":
                    layer1_size = st.slider("ç¬¬ä¸€å±‚ç¥ç»å…ƒæ•°", 10, 200, 100, key=f"mlp_l1_{i}")
                    layer2_size = st.slider("ç¬¬äºŒå±‚ç¥ç»å…ƒæ•°", 10, 100, 50, key=f"mlp_l2_{i}")
                    hidden_layer_sizes = (layer1_size, layer2_size)
                else:  # ä¸‰å±‚
                    layer1_size = st.slider("ç¬¬ä¸€å±‚ç¥ç»å…ƒæ•°", 10, 200, 100, key=f"mlp_l1_{i}")
                    layer2_size = st.slider("ç¬¬äºŒå±‚ç¥ç»å…ƒæ•°", 10, 100, 50, key=f"mlp_l2_{i}")
                    layer3_size = st.slider("ç¬¬ä¸‰å±‚ç¥ç»å…ƒæ•°", 10, 50, 25, key=f"mlp_l3_{i}")
                    hidden_layer_sizes = (layer1_size, layer2_size, layer3_size)
                
                activation = st.selectbox("æ¿€æ´»å‡½æ•°", ['relu', 'tanh', 'logistic'], 
                                        index=0, key=f"mlp_activation_{i}")
            
            with col2:
                solver = st.selectbox("ä¼˜åŒ–ç®—æ³•", ['adam', 'lbfgs', 'sgd'], 
                                    index=0, key=f"mlp_solver_{i}")
                learning_rate_init = st.selectbox("åˆå§‹å­¦ä¹ ç‡", [0.0001, 0.001, 0.01], 
                                                index=1, key=f"mlp_lr_{i}")
                max_iter = st.slider("æœ€å¤§è¿­ä»£æ¬¡æ•°", 100, 1000, 500, key=f"mlp_iter_{i}")
                alpha = st.selectbox("L2æ­£åˆ™åŒ–å‚æ•°", [0.0001, 0.001, 0.01], 
                                   index=0, key=f"mlp_alpha_{i}")
            
            random_state = st.number_input("éšæœºç§å­", value=42, key=f"mlp_seed_{i}")
            
            model_params['mlp'] = {
                'hidden_layer_sizes': hidden_layer_sizes,
                'activation': activation,
                'solver': solver,
                'learning_rate_init': learning_rate_init,
                'max_iter': max_iter,
                'alpha': alpha,
                'random_state': random_state
            }
        
        elif model_name == 'xgb':
            # XGBoostå‚æ•°
            col1, col2 = st.columns(2)
            with col1:
                n_estimators = st.slider("æå‡è½®æ•°", 50, 500, 100, key=f"xgb_trees_{i}")
                learning_rate = st.selectbox("å­¦ä¹ ç‡", [0.01, 0.05, 0.1, 0.2], 
                                           index=2, key=f"xgb_lr_{i}")
                max_depth = st.slider("æœ€å¤§æ·±åº¦", 2, 10, 6, key=f"xgb_depth_{i}")
            with col2:
                subsample = st.slider("å­é‡‡æ ·æ¯”ä¾‹", 0.5, 1.0, 1.0, step=0.1, key=f"xgb_subsample_{i}")
                colsample_bytree = st.slider("ç‰¹å¾é‡‡æ ·æ¯”ä¾‹", 0.5, 1.0, 1.0, step=0.1, key=f"xgb_colsample_{i}")
                reg_alpha = st.selectbox("L1æ­£åˆ™åŒ–", [0, 0.01, 0.1], index=0, key=f"xgb_alpha_{i}")
            
            random_state = st.number_input("éšæœºç§å­", value=42, key=f"xgb_seed_{i}")
            
            model_params['xgb'] = {
                'n_estimators': n_estimators,
                'learning_rate': learning_rate,
                'max_depth': max_depth,
                'subsample': subsample,
                'colsample_bytree': colsample_bytree,
                'reg_alpha': reg_alpha,
                'random_state': random_state
            }
    
    # äº¤å‰éªŒè¯è®¾ç½®æ˜¾ç¤º
    if st.session_state.split_method in ["KFoldäº¤å‰éªŒè¯", "ç•™ä¸€æ³•(LOOCV)"]:
        use_cv = True
        if st.session_state.split_method == "KFoldäº¤å‰éªŒè¯":
            cv_folds = getattr(st.session_state, 'cv_splits', 5)
            st.info(f"å°†ä½¿ç”¨ {cv_folds} æŠ˜äº¤å‰éªŒè¯")
        else:
            st.info("å°†ä½¿ç”¨ç•™ä¸€æ³•äº¤å‰éªŒè¯")
    else:
        use_cv = False
        st.info("å°†ä½¿ç”¨è®­ç»ƒé›†/æµ‹è¯•é›†åˆ’åˆ†")
    
    # å¼€å§‹è®­ç»ƒ
    if st.button("ğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹", type="primary"):
        if not selected_models:
            st.error("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ¨¡å‹ï¼")
            return
        
        X_train = st.session_state.X_train
        y_train = st.session_state.y_train
        
        if st.session_state.split_method == "éšæœºåˆ’åˆ†":
            X_test = st.session_state.X_test
            y_test = st.session_state.y_test
        else:
            X_test = X_train
            y_test = y_train
        
        results = []
        trained_models = {}
        detailed_results = {}
        
        progress_bar = st.progress(0)
        progress_text = st.empty()
        
        for i, model_name in enumerate(selected_models):
            progress_text.text(f"æ­£åœ¨è®­ç»ƒ {available_models[model_name]} ({i+1}/{len(selected_models)})...")
            
            try:
                # åˆ›å»ºæ¨¡å‹
                params = model_params.get(model_name, {})
                
                # å¤„ç†æ ‡å‡†åŒ–
                use_scaler = params.pop('use_scaler', False)
                scaler = None
                X_train_scaled = X_train
                X_test_scaled = X_test
                
                if use_scaler and model_name in ['ridge', 'lasso', 'linear']:
                    scaler = StandardScaler()
                    X_train_scaled = scaler.fit_transform(X_train)
                    X_test_scaled = scaler.transform(X_test)
                
                # åˆ›å»ºå…·ä½“æ¨¡å‹
                if model_name == 'linear':
                    model = LinearRegression(**params)
                elif model_name == 'ridge':
                    base_model = Ridge(**params)
                    model = MultiOutputRegressor(base_model) if is_multioutput else base_model
                elif model_name == 'lasso':
                    base_model = Lasso(**params)
                    model = MultiOutputRegressor(base_model) if is_multioutput else base_model
                elif model_name == 'svr':
                    base_model = SVR(**params)
                    model = MultiOutputRegressor(base_model) if is_multioutput else base_model
                elif model_name == 'rf':
                    model = RandomForestRegressor(**params)
                elif model_name == 'gbr':
                    base_model = GradientBoostingRegressor(**params)
                    model = MultiOutputRegressor(base_model) if is_multioutput else base_model
                elif model_name == 'pls':
                    model = PLSRegression(**params)
                elif model_name == 'mlp':
                    base_model = MLPRegressor(**params)
                    model = MultiOutputRegressor(base_model) if is_multioutput else base_model
                elif model_name == 'xgb':
                    try:
                        from xgboost import XGBRegressor
                        base_model = XGBRegressor(**params)
                        model = MultiOutputRegressor(base_model) if is_multioutput else base_model
                    except ImportError:
                        st.error("XGBoostæœªå®‰è£…ï¼Œè·³è¿‡è¯¥æ¨¡å‹")
                        continue
                
                # è®­ç»ƒæ¨¡å‹
                start_time = time.time()
                
                if use_cv:
                    # äº¤å‰éªŒè¯
                    if st.session_state.split_method == "KFoldäº¤å‰éªŒè¯":
                        cv = KFold(n_splits=cv_folds, shuffle=True, random_state=42)
                    else:  # LOOCV
                        cv = LeaveOneOut()
                    
                    # æ‰§è¡Œäº¤å‰éªŒè¯
                    cv_predictions = np.zeros_like(y_train)
                    cv_scores = []
                    
                    for fold, (train_idx, val_idx) in enumerate(cv.split(X_train)):
                        X_fold_train = X_train_scaled[train_idx]
                        X_fold_val = X_train_scaled[val_idx]
                        y_fold_train = y_train[train_idx]
                        y_fold_val = y_train[val_idx]
                        
                        # è®­ç»ƒ
                        model.fit(X_fold_train, y_fold_train)
                        
                        # é¢„æµ‹
                        fold_pred = model.predict(X_fold_val)
                        cv_predictions[val_idx] = fold_pred
                        
                        # è®¡ç®—foldå¾—åˆ†
                        if is_multioutput:
                            fold_score = np.mean([r2_score(y_fold_val[:, j], fold_pred[:, j]) 
                                                for j in range(y_fold_val.shape[1])])
                        else:
                            fold_score = r2_score(y_fold_val, fold_pred)
                        cv_scores.append(fold_score)
                    
                    # ç”¨å…¨éƒ¨æ•°æ®é‡æ–°è®­ç»ƒ
                    model.fit(X_train_scaled, y_train)
                    train_pred = cv_predictions
                    test_pred = model.predict(X_test_scaled)
                    
                    cv_mean = np.mean(cv_scores)
                    cv_std = np.std(cv_scores)
                    
                else:
                    # æ™®é€šè®­ç»ƒ
                    model.fit(X_train_scaled, y_train)
                    train_pred = model.predict(X_train_scaled)
                    test_pred = model.predict(X_test_scaled)
                    cv_mean = cv_std = None
                
                train_time = time.time() - start_time
                
                # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
                if is_multioutput:
                    # å¤šè¾“å‡º
                    train_r2_scores = [r2_score(y_train[:, j], train_pred[:, j]) for j in range(y_train.shape[1])]
                    test_r2_scores = [r2_score(y_test[:, j], test_pred[:, j]) for j in range(y_test.shape[1])]
                    train_rmse_scores = [np.sqrt(mean_squared_error(y_train[:, j], train_pred[:, j])) for j in range(y_train.shape[1])]
                    test_rmse_scores = [np.sqrt(mean_squared_error(y_test[:, j], test_pred[:, j])) for j in range(y_test.shape[1])]
                    train_mae_scores = [mean_absolute_error(y_train[:, j], train_pred[:, j]) for j in range(y_train.shape[1])]
                    test_mae_scores = [mean_absolute_error(y_test[:, j], test_pred[:, j]) for j in range(y_test.shape[1])]
                    
                    train_r2 = np.mean(train_r2_scores)
                    test_r2 = np.mean(test_r2_scores)
                    train_rmse = np.mean(train_rmse_scores)
                    test_rmse = np.mean(test_rmse_scores)
                    train_mae = np.mean(train_mae_scores)
                    test_mae = np.mean(test_mae_scores)
                    
                    detailed_results[model_name] = {
                        'train_r2_per_target': train_r2_scores,
                        'test_r2_per_target': test_r2_scores,
                        'train_rmse_per_target': train_rmse_scores,
                        'test_rmse_per_target': test_rmse_scores,
                        'train_mae_per_target': train_mae_scores,
                        'test_mae_per_target': test_mae_scores,
                        'train_pred': train_pred,
                        'test_pred': test_pred,
                        'params': params,
                        'scaler': scaler
                    }
                else:
                    # å•è¾“å‡º
                    train_r2 = r2_score(y_train, train_pred)
                    test_r2 = r2_score(y_test, test_pred)
                    train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))
                    test_rmse = np.sqrt(mean_squared_error(y_test, test_pred))
                    train_mae = mean_absolute_error(y_train, train_pred)
                    test_mae = mean_absolute_error(y_test, test_pred)
                    
                    detailed_results[model_name] = {
                        'train_pred': train_pred,
                        'test_pred': test_pred,
                        'params': params,
                        'scaler': scaler
                    }
                
                # ä¿å­˜ç»“æœ
                result_entry = {
                    'Model': available_models[model_name],
                    'Train RÂ²': train_r2,
                    'Test RÂ²': test_r2,
                    'Train RMSE': train_rmse,
                    'Test RMSE': test_rmse,
                    'Train MAE': train_mae,
                    'Test MAE': test_mae,
                    'Training Time (s)': train_time
                }
                
                if use_cv:
                    result_entry['CV RÂ² Mean'] = cv_mean
                    result_entry['CV RÂ² Std'] = cv_std
                
                results.append(result_entry)
                trained_models[model_name] = model
                
                progress_bar.progress((i + 1) / len(selected_models))
                
            except Exception as e:
                st.error(f"è®­ç»ƒæ¨¡å‹ {available_models[model_name]} æ—¶å‡ºé”™: {e}")
                st.error(traceback.format_exc())
                continue
        
        progress_text.text("æ‰€æœ‰æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
        
        if results:
            # æ˜¾ç¤ºç»“æœ
            results_df = pd.DataFrame(results)
            results_df = results_df.sort_values('Test RÂ²', ascending=False)
            
            st.session_state.trained_models = trained_models
            st.session_state.results_df = results_df
            st.session_state.detailed_results = detailed_results
            
            st.success("ğŸ‰ æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°å®Œæˆï¼")
            
            # æ˜¾ç¤ºæ€§èƒ½æ¯”è¾ƒè¡¨æ ¼
            st.subheader("ğŸ“Š æ¨¡å‹æ€§èƒ½æ¯”è¾ƒ")
            
            # æ ¼å¼åŒ–æ˜¾ç¤º
            display_df = results_df.copy()
            numeric_cols = ['Train RÂ²', 'Test RÂ²', 'Train RMSE', 'Test RMSE', 'Train MAE', 'Test MAE', 'Training Time (s)']
            if use_cv:
                numeric_cols.extend(['CV RÂ² Mean', 'CV RÂ² Std'])
            
            for col in numeric_cols:
                if col in display_df.columns:
                    if 'Time' in col:
                        display_df[col] = display_df[col].apply(lambda x: f"{x:.3f}s")
                    else:
                        display_df[col] = display_df[col].apply(lambda x: f"{x:.4f}")
            
            st.dataframe(display_df, use_container_width=True)
            
            # æ˜¾ç¤ºæœ€ä½³æ¨¡å‹
            best_model_idx = results_df['Test RÂ²'].idxmax()
            best_model_name = results_df.loc[best_model_idx, 'Model']
            st.success(f"ğŸ† æœ€ä½³æ¨¡å‹: {best_model_name} (Test RÂ² = {results_df.loc[best_model_idx, 'Test RÂ²']:.4f})")
            
            # æ˜¾ç¤ºæ¨¡å‹æ€§èƒ½å¯è§†åŒ–
            show_model_performance_visualization(results_df, detailed_results, is_multioutput)
            
        else:
            st.error("âŒ æ²¡æœ‰æˆåŠŸè®­ç»ƒä»»ä½•æ¨¡å‹ï¼Œè¯·æ£€æŸ¥æ•°æ®å’Œå‚æ•°è®¾ç½®")

def show_model_performance_visualization(results_df, detailed_results, is_multioutput):
    """æ˜¾ç¤ºæ¨¡å‹æ€§èƒ½å¯è§†åŒ–"""
    st.subheader("ğŸ“ˆ æ¨¡å‹æ€§èƒ½å¯è§†åŒ–")
    
    # åˆ›å»ºæ ‡ç­¾é¡µ
    if is_multioutput:
        tab1, tab2, tab3 = st.tabs(["æ€§èƒ½å¯¹æ¯”", "é¢„æµ‹æ•ˆæœ", "ç›®æ ‡å˜é‡è¯¦æƒ…"])
    else:
        tab1, tab2 = st.tabs(["æ€§èƒ½å¯¹æ¯”", "é¢„æµ‹æ•ˆæœ"])
    
    with tab1:
        # æ€§èƒ½å¯¹æ¯”å›¾
        col1, col2 = st.columns(2)
        
        with col1:
            # RÂ²å¯¹æ¯”
            fig, ax = plt.subplots(figsize=(10, 6))
            models = results_df['Model']
            test_r2 = results_df['Test RÂ²'].astype(float)
            train_r2 = results_df['Train RÂ²'].astype(float)
            
            y_pos = np.arange(len(models))
            width = 0.35
            
            ax.barh(y_pos - width/2, train_r2, width, label='è®­ç»ƒ RÂ²', alpha=0.7, color='skyblue')
            ax.barh(y_pos + width/2, test_r2, width, label='æµ‹è¯• RÂ²', alpha=0.7, color='lightcoral')
            
            ax.set_yticks(y_pos)
            ax.set_yticklabels(models)
            ax.set_xlabel('RÂ² åˆ†æ•°')
            ax.set_title('æ¨¡å‹ RÂ² æ€§èƒ½å¯¹æ¯”')
            ax.legend()
            ax.grid(True, linestyle='--', alpha=0.7)
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for i, (train, test) in enumerate(zip(train_r2, test_r2)):
                ax.text(train + 0.01, i - width/2, f'{train:.3f}', va='center', fontsize=8)
                ax.text(test + 0.01, i + width/2, f'{test:.3f}', va='center', fontsize=8)
            
            st.pyplot(fig)
        
        with col2:
            # RMSEå¯¹æ¯”
            fig, ax = plt.subplots(figsize=(10, 6))
            test_rmse = results_df['Test RMSE'].astype(float)
            train_rmse = results_df['Train RMSE'].astype(float)
            
            ax.barh(y_pos - width/2, train_rmse, width, label='è®­ç»ƒ RMSE', alpha=0.7, color='lightgreen')
            ax.barh(y_pos + width/2, test_rmse, width, label='æµ‹è¯• RMSE', alpha=0.7, color='orange')
            
            ax.set_yticks(y_pos)
            ax.set_yticklabels(models)
            ax.set_xlabel('RMSE')
            ax.set_title('æ¨¡å‹ RMSE æ€§èƒ½å¯¹æ¯”')
            ax.legend()
            ax.grid(True, linestyle='--', alpha=0.7)
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for i, (train, test) in enumerate(zip(train_rmse, test_rmse)):
                ax.text(train + max(train_rmse) * 0.01, i - width/2, f'{train:.3f}', va='center', fontsize=8)
                ax.text(test + max(test_rmse) * 0.01, i + width/2, f'{test:.3f}', va='center', fontsize=8)
            
            st.pyplot(fig)
    
    with tab2:
        # é¢„æµ‹æ•ˆæœæ•£ç‚¹å›¾
        st.write("### ğŸ¯ é¢„æµ‹ vs å®é™…å€¼å¯¹æ¯”")
        
        # é€‰æ‹©æ¨¡å‹
        model_names = list(detailed_results.keys())
        available_models = {
            'linear': 'çº¿æ€§å›å½’', 'ridge': 'å²­å›å½’', 'lasso': 'Lassoå›å½’',
            'svr': 'æ”¯æŒå‘é‡å›å½’', 'rf': 'éšæœºæ£®æ—', 'gbr': 'æ¢¯åº¦æå‡å›å½’',
            'mlp': 'å¤šå±‚æ„ŸçŸ¥æœº', 'pls': 'åæœ€å°äºŒä¹˜å›å½’', 'xgb': 'XGBoost'
        }
        
        selected_model = st.selectbox(
            "é€‰æ‹©æ¨¡å‹æŸ¥çœ‹é¢„æµ‹æ•ˆæœ", 
            model_names, 
            format_func=lambda x: available_models.get(x, x)
        )
        
        if selected_model in detailed_results:
            model_results = detailed_results[selected_model]
            
            # è·å–å®é™…å€¼
            y_train = st.session_state.y_train
            y_test = st.session_state.y_test if st.session_state.y_test is not None else y_train
            
            if is_multioutput:
                # å¤šè¾“å‡ºæƒ…å†µ
                target_names = st.session_state.selected_cols
                target_idx = st.selectbox(
                    "é€‰æ‹©ç›®æ ‡å˜é‡", 
                    range(len(target_names)), 
                    format_func=lambda x: target_names[x]
                )
                
                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
                
                # è®­ç»ƒé›†é¢„æµ‹
                y_train_actual = y_train[:, target_idx]
                y_train_pred = model_results['train_pred'][:, target_idx]
                
                ax1.scatter(y_train_actual, y_train_pred, alpha=0.6, color='blue')
                ax1.plot([y_train_actual.min(), y_train_actual.max()], 
                        [y_train_actual.min(), y_train_actual.max()], 'r--', lw=2)
                ax1.set_xlabel('å®é™…å€¼')
                ax1.set_ylabel('é¢„æµ‹å€¼')
                ax1.set_title(f'è®­ç»ƒé›† - {target_names[target_idx]}')
                ax1.grid(True, alpha=0.3)
                
                # æ·»åŠ RÂ²å’ŒRMSE
                r2 = r2_score(y_train_actual, y_train_pred)
                rmse = np.sqrt(mean_squared_error(y_train_actual, y_train_pred))
                ax1.text(0.05, 0.95, f'RÂ² = {r2:.3f}\nRMSE = {rmse:.3f}', 
                        transform=ax1.transAxes, verticalalignment='top',
                        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
                
                # æµ‹è¯•é›†é¢„æµ‹
                y_test_actual = y_test[:, target_idx]
                y_test_pred = model_results['test_pred'][:, target_idx]
                
                ax2.scatter(y_test_actual, y_test_pred, alpha=0.6, color='green')
                ax2.plot([y_test_actual.min(), y_test_actual.max()], 
                        [y_test_actual.min(), y_test_actual.max()], 'r--', lw=2)
                ax2.set_xlabel('å®é™…å€¼')
                ax2.set_ylabel('é¢„æµ‹å€¼')
                ax2.set_title(f'æµ‹è¯•é›† - {target_names[target_idx]}')
                ax2.grid(True, alpha=0.3)
                
                # æ·»åŠ RÂ²å’ŒRMSE
                r2 = r2_score(y_test_actual, y_test_pred)
                rmse = np.sqrt(mean_squared_error(y_test_actual, y_test_pred))
                ax2.text(0.05, 0.95, f'RÂ² = {r2:.3f}\nRMSE = {rmse:.3f}', 
                        transform=ax2.transAxes, verticalalignment='top',
                        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
                
                plt.tight_layout()
                st.pyplot(fig)
                
            else:
                # å•è¾“å‡ºæƒ…å†µ
                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
                
                # è®­ç»ƒé›†
                ax1.scatter(y_train, model_results['train_pred'], alpha=0.6, color='blue')
                ax1.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=2)
                ax1.set_xlabel('å®é™…å€¼')
                ax1.set_ylabel('é¢„æµ‹å€¼')
                ax1.set_title('è®­ç»ƒé›†é¢„æµ‹æ•ˆæœ')
                ax1.grid(True, alpha=0.3)
                
                r2 = r2_score(y_train, model_results['train_pred'])
                rmse = np.sqrt(mean_squared_error(y_train, model_results['train_pred']))
                ax1.text(0.05, 0.95, f'RÂ² = {r2:.3f}\nRMSE = {rmse:.3f}', 
                        transform=ax1.transAxes, verticalalignment='top',
                        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
                
                # æµ‹è¯•é›†
                ax2.scatter(y_test, model_results['test_pred'], alpha=0.6, color='green')
                ax2.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
                ax2.set_xlabel('å®é™…å€¼')
                ax2.set_ylabel('é¢„æµ‹å€¼')
                ax2.set_title('æµ‹è¯•é›†é¢„æµ‹æ•ˆæœ')
                ax2.grid(True, alpha=0.3)
                
                r2 = r2_score(y_test, model_results['test_pred'])
                rmse = np.sqrt(mean_squared_error(y_test, model_results['test_pred']))
                ax2.text(0.05, 0.95, f'RÂ² = {r2:.3f}\nRMSE = {rmse:.3f}', 
                        transform=ax2.transAxes, verticalalignment='top',
                        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
                
                plt.tight_layout()
                st.pyplot(fig)
    
    if is_multioutput:
        with tab3:
            # å„ç›®æ ‡å˜é‡çš„è¯¦ç»†æ€§èƒ½
            st.write("### ğŸ“Š å„ç›®æ ‡å˜é‡æ€§èƒ½è¯¦æƒ…")
            
            # é€‰æ‹©æ¨¡å‹
            selected_model = st.selectbox(
                "é€‰æ‹©æ¨¡å‹", 
                model_names, 
                format_func=lambda x: available_models.get(x, x),
                key="detail_model_select"
            )
            
            if selected_model in detailed_results:
                model_results = detailed_results[selected_model]
                target_names = st.session_state.selected_cols
                
                # åˆ›å»ºè¯¦ç»†ç»“æœè¡¨æ ¼
                target_results = []
                for i, target_name in enumerate(target_names):
                    target_results.append({
                        'ç›®æ ‡å˜é‡': target_name,
                        'è®­ç»ƒ RÂ²': f"{model_results['train_r2_per_target'][i]:.4f}",
                        'æµ‹è¯• RÂ²': f"{model_results['test_r2_per_target'][i]:.4f}",
                        'è®­ç»ƒ RMSE': f"{model_results['train_rmse_per_target'][i]:.4f}",
                        'æµ‹è¯• RMSE': f"{model_results['test_rmse_per_target'][i]:.4f}",
                        'è®­ç»ƒ MAE': f"{model_results['train_mae_per_target'][i]:.4f}",
                        'æµ‹è¯• MAE': f"{model_results['test_mae_per_target'][i]:.4f}"
                    })
                
                target_df = pd.DataFrame(target_results)
                st.dataframe(target_df, use_container_width=True)
                
                # å¯è§†åŒ–å„ç›®æ ‡å˜é‡æ€§èƒ½
                fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
                
                # RÂ²å¯¹æ¯”
                ax1.bar(target_names, model_results['train_r2_per_target'], 
                       alpha=0.7, label='è®­ç»ƒ RÂ²', color='skyblue')
                ax1.bar(target_names, model_results['test_r2_per_target'], 
                       alpha=0.7, label='æµ‹è¯• RÂ²', color='lightcoral')
                ax1.set_ylabel('RÂ²')
                ax1.set_title('å„ç›®æ ‡å˜é‡ RÂ² å¯¹æ¯”')
                ax1.legend()
                ax1.tick_params(axis='x', rotation=45)
                ax1.grid(True, alpha=0.3)
                
                # RMSEå¯¹æ¯”
                ax2.bar(target_names, model_results['train_rmse_per_target'], 
                       alpha=0.7, label='è®­ç»ƒ RMSE', color='lightgreen')
                ax2.bar(target_names, model_results['test_rmse_per_target'], 
                       alpha=0.7, label='æµ‹è¯• RMSE', color='orange')
                ax2.set_ylabel('RMSE')
                ax2.set_title('å„ç›®æ ‡å˜é‡ RMSE å¯¹æ¯”')
                ax2.legend()
                ax2.tick_params(axis='x', rotation=45)
                ax2.grid(True, alpha=0.3)
                
                # MAEå¯¹æ¯”
                ax3.bar(target_names, model_results['train_mae_per_target'], 
                       alpha=0.7, label='è®­ç»ƒ MAE', color='plum')
                ax3.bar(target_names, model_results['test_mae_per_target'], 
                       alpha=0.7, label='æµ‹è¯• MAE', color='gold')
                ax3.set_ylabel('MAE')
                ax3.set_title('å„ç›®æ ‡å˜é‡ MAE å¯¹æ¯”')
                ax3.legend()
                ax3.tick_params(axis='x', rotation=45)
                ax3.grid(True, alpha=0.3)
                
                # ç»¼åˆæ€§èƒ½é›·è¾¾å›¾
                from math import pi
                
                # å½’ä¸€åŒ–æ€§èƒ½æŒ‡æ ‡
                r2_norm = np.array(model_results['test_r2_per_target'])
                rmse_norm = 1 - np.array(model_results['test_rmse_per_target']) / max(model_results['test_rmse_per_target'])
                mae_norm = 1 - np.array(model_results['test_mae_per_target']) / max(model_results['test_mae_per_target'])
                
                # é›·è¾¾å›¾
                angles = [n / len(target_names) * 2 * pi for n in range(len(target_names))]
                angles += angles[:1]
                
                ax4 = plt.subplot(224, projection='polar')
                
                r2_values = list(r2_norm) + [r2_norm[0]]
                rmse_values = list(rmse_norm) + [rmse_norm[0]]
                mae_values = list(mae_norm) + [mae_norm[0]]
                
                ax4.plot(angles, r2_values, 'o-', linewidth=2, label='RÂ² (æ ‡å‡†åŒ–)', color='blue')
                ax4.fill(angles, r2_values, alpha=0.25, color='blue')
                
                ax4.plot(angles, rmse_values, 'o-', linewidth=2, label='RMSE (æ ‡å‡†åŒ–)', color='red')
                ax4.fill(angles, rmse_values, alpha=0.25, color='red')
                
                ax4.plot(angles, mae_values, 'o-', linewidth=2, label='MAE (æ ‡å‡†åŒ–)', color='green')
                ax4.fill(angles, mae_values, alpha=0.25, color='green')
                
                ax4.set_xticks(angles[:-1])
                ax4.set_xticklabels(target_names)
                ax4.set_ylim(0, 1)
                ax4.set_title('ç»¼åˆæ€§èƒ½é›·è¾¾å›¾', pad=20)
                ax4.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))
                
                plt.tight_layout()
                st.pyplot(fig)

def show_blind_prediction_page():
    """ç›²æ ·é¢„æµ‹é¡µé¢"""
    st.markdown("<h1 class='section-header'>ç›²æ ·é¢„æµ‹</h1>", unsafe_allow_html=True)
    
    if not hasattr(st.session_state, 'trained_models') or not st.session_state.trained_models:
        st.warning("è¯·å…ˆè®­ç»ƒæ¨¡å‹")
        return
    
    if st.session_state.X_preprocessed is None:
        st.warning("è¯·å…ˆå®Œæˆæ•°æ®é¢„å¤„ç†")
        return
    
    st.markdown("""
    <div class="info-box">
    ä¸Šä¼ ç›²æ ·æ•°æ®æ–‡ä»¶è¿›è¡Œé¢„æµ‹ã€‚ç›²æ ·æ•°æ®å°†ä½¿ç”¨ä¸è®­ç»ƒæ•°æ®ç›¸åŒçš„é¢„å¤„ç†æµç¨‹ã€‚
    </div>
    """, unsafe_allow_html=True)
    
    # æ˜¾ç¤ºé¢„å¤„ç†å‚æ•°ä¿¡æ¯
    st.subheader("å½“å‰é¢„å¤„ç†å‚æ•°")
    params = st.session_state.preprocessing_params
    
    with st.expander("æŸ¥çœ‹è¯¦ç»†å‚æ•°"):
        st.json(params)
    
    # æ˜¾ç¤ºç‰¹å¾é€‰æ‹©ä¿¡æ¯
    if hasattr(st.session_state, 'feature_selected') and st.session_state.feature_selected:
        if st.session_state.feature_selection_method != "ä¸è¿›è¡Œç‰¹å¾é€‰æ‹©":
            st.info(f"âœ… å·²è¿›è¡Œç‰¹å¾é€‰æ‹©ï¼š{st.session_state.feature_selection_method}")
            st.info(f"ç‰¹å¾æ•°é‡ï¼š{st.session_state.X_preprocessed.shape[1]} â†’ {st.session_state.X_final.shape[1]}")
        else:
            st.info("â„¹ï¸ æœªè¿›è¡Œç‰¹å¾é€‰æ‹©ï¼Œä½¿ç”¨å…¨éƒ¨é¢„å¤„ç†åçš„ç‰¹å¾")
    
    # ä¸Šä¼ ç›²æ ·æ•°æ®æ–‡ä»¶
    blind_file = st.file_uploader("ä¸Šä¼ ç›²æ ·æ•°æ®æ–‡ä»¶", type=["csv", "xlsx", "xls"])
    
    if blind_file is not None:
        try:
            # è¯»å–ç›²æ ·æ•°æ®
            if blind_file.name.endswith('.csv'):
                blind_df = pd.read_csv(blind_file)
            else:
                blind_df = pd.read_excel(blind_file)
            
            st.success(f"ç›²æ ·æ•°æ®ä¸Šä¼ æˆåŠŸï¼å…±{blind_df.shape[0]}è¡Œï¼Œ{blind_df.shape[1]}åˆ—")
            st.dataframe(blind_df.head())
            
            # æ£€æŸ¥æ•°æ®æ ¼å¼
            st.subheader("æ•°æ®æ ¼å¼æ£€æŸ¥")
            
            # è¯†åˆ«æ³¢æ•°åˆ—
            try:
                potential_wavenumbers = blind_df.columns[2:]
                numeric_columns = []
                
                for col in potential_wavenumbers:
                    try:
                        float(col)
                        numeric_columns.append(col)
                    except ValueError:
                        continue
                
                if len(numeric_columns) < 10:
                    st.error("æ£€æµ‹åˆ°çš„æ³¢æ•°åˆ—æ•°é‡ä¸è¶³ï¼Œè¯·æ£€æŸ¥æ•°æ®æ ¼å¼")
                    return
                
                blind_wavenumbers = pd.Series(numeric_columns).astype(float)
                st.info(f"ç›²æ ·æ•°æ®æ³¢æ•°èŒƒå›´: {blind_wavenumbers.min():.1f} ~ {blind_wavenumbers.max():.1f} cmâ»Â¹")
                
                # ä¸è®­ç»ƒæ•°æ®çš„æ³¢æ•°èŒƒå›´å¯¹æ¯”
                train_wavenumbers = st.session_state.wavenumbers
                st.info(f"è®­ç»ƒæ•°æ®æ³¢æ•°èŒƒå›´: {train_wavenumbers.min():.1f} ~ {train_wavenumbers.max():.1f} cmâ»Â¹")
                
                # æ£€æŸ¥æ³¢æ•°èŒƒå›´å…¼å®¹æ€§
                if (blind_wavenumbers.min() > train_wavenumbers.min() or 
                    blind_wavenumbers.max() < train_wavenumbers.max()):
                    st.warning("âš ï¸ ç›²æ ·æ•°æ®çš„æ³¢æ•°èŒƒå›´ä¸è®­ç»ƒæ•°æ®ä¸å®Œå…¨åŒ¹é…ï¼Œå¯èƒ½å½±å“é¢„æµ‹ç²¾åº¦")
                
                # æå–ç›²æ ·å…‰è°±æ•°æ®
                blind_spectra = blind_df[numeric_columns].values.astype(float)
                st.info(f"åŸå§‹ç›²æ ·å…‰è°±å½¢çŠ¶: {blind_spectra.shape}")
                
                # é€‰æ‹©è¦ä½¿ç”¨çš„æ¨¡å‹
                st.subheader("æ¨¡å‹é€‰æ‹©")
                model_names = list(st.session_state.trained_models.keys())
                available_models = {
                    'linear': 'çº¿æ€§å›å½’', 'ridge': 'å²­å›å½’', 'lasso': 'Lassoå›å½’',
                    'svr': 'æ”¯æŒå‘é‡å›å½’', 'rf': 'éšæœºæ£®æ—', 'gbr': 'æ¢¯åº¦æå‡å›å½’',
                    'mlp': 'å¤šå±‚æ„ŸçŸ¥æœº', 'pls': 'åæœ€å°äºŒä¹˜å›å½’', 'xgb': 'XGBoost'
                }
                
                selected_model_key = st.selectbox(
                    "é€‰æ‹©é¢„æµ‹æ¨¡å‹", 
                    model_names,
                    format_func=lambda x: available_models.get(x, x)
                )
                
                if st.button("è¿›è¡Œé¢„æµ‹"):
                    with st.spinner("æ­£åœ¨åº”ç”¨é¢„å¤„ç†æµç¨‹å¹¶è¿›è¡Œé¢„æµ‹..."):
                        try:
                            # åº”ç”¨é¢„å¤„ç†æµç¨‹
                            st.write("**é¢„å¤„ç†æ­¥éª¤:**")
                            
                            # 1. æˆªå–æ³¢æ•°èŒƒå›´
                            start_wn = params['start_wavenumber']
                            end_wn = params['end_wavenumber']
                            
                            start_idx = np.argmin(np.abs(blind_wavenumbers - start_wn))
                            end_idx = np.argmin(np.abs(blind_wavenumbers - end_wn)) + 1
                            
                            blind_wavenumbers_crop = blind_wavenumbers[start_idx:end_idx]
                            blind_X_crop = blind_spectra[:, start_idx:end_idx]
                            
                            st.write(f"âœ“ æ³¢æ•°æˆªå–: {start_wn} ~ {end_wn} cmâ»Â¹, å½¢çŠ¶: {blind_X_crop.shape}")
                            
                            # 2. å¹³æ»‘å¤„ç†
                            if params.get('apply_smooth', True):
                                blind_X_smooth = np.zeros_like(blind_X_crop)
                                for i in range(blind_X_crop.shape[0]):
                                    blind_X_smooth[i] = savgol_filter(
                                        blind_X_crop[i], 
                                        params['smooth_window'], 
                                        params['smooth_poly']
                                    )
                                st.write(f"âœ“ Savitzky-Golayå¹³æ»‘: çª—å£={params['smooth_window']}, å¤šé¡¹å¼é˜¶æ•°={params['smooth_poly']}")
                            else:
                                blind_X_smooth = blind_X_crop.copy()
                                st.write("â—‹ è·³è¿‡å¹³æ»‘å¤„ç†")
                            
                            # 3. åŸºçº¿æ ¡æ­£
                            if params.get('apply_baseline', True):
                                corrector = SpectrumBaselineCorrector()
                                blind_X_corr = np.zeros_like(blind_X_smooth)
                                
                                baseline_method = params['baseline_method']
                                baseline_params = params['baseline_params']
                                
                                for i in range(blind_X_smooth.shape[0]):
                                    try:
                                        baseline, corrected = corrector.correct_baseline(
                                            blind_X_smooth[i], 
                                            baseline_method, 
                                            **baseline_params
                                        )
                                        blind_X_corr[i] = corrected
                                    except Exception as e:
                                        st.warning(f"æ ·æœ¬ {i+1} åŸºçº¿æ ¡æ­£å¤±è´¥ï¼Œä½¿ç”¨å¹³æ»‘åçš„æ•°æ®: {e}")
                                        blind_X_corr[i] = blind_X_smooth[i]
                                
                                st.write(f"âœ“ åŸºçº¿æ ¡æ­£: {baseline_method.upper()}ç®—æ³•")
                            else:
                                blind_X_corr = blind_X_smooth.copy()
                                st.write("â—‹ è·³è¿‡åŸºçº¿æ ¡æ­£")
                            
                            # 4. å½’ä¸€åŒ–
                            if params.get('apply_normalize', True):
                                blind_X_norm = np.zeros_like(blind_X_corr)
                                normalize_method = params['normalize_method']
                                
                                for i in range(blind_X_corr.shape[0]):
                                    if normalize_method == 'area':
                                        total_area = np.trapz(np.abs(blind_X_corr[i]), blind_wavenumbers_crop)
                                        blind_X_norm[i] = blind_X_corr[i] / (total_area if total_area != 0 else 1e-9)
                                    elif normalize_method == 'max':
                                        max_val = np.max(np.abs(blind_X_corr[i]))
                                        blind_X_norm[i] = blind_X_corr[i] / (max_val if max_val != 0 else 1e-9)
                                    elif normalize_method == 'vector':
                                        norm_val = np.linalg.norm(blind_X_corr[i])
                                        blind_X_norm[i] = blind_X_corr[i] / (norm_val if norm_val != 0 else 1e-9)
                                    elif normalize_method == 'minmax':
                                        min_val, max_val = np.min(blind_X_corr[i]), np.max(blind_X_corr[i])
                                        if max_val - min_val == 0:
                                            blind_X_norm[i] = blind_X_corr[i]
                                        else:
                                            blind_X_norm[i] = (blind_X_corr[i] - min_val) / (max_val - min_val)
                                
                                st.write(f"âœ“ å½’ä¸€åŒ–: {normalize_method}æ–¹æ³•")
                            else:
                                blind_X_norm = blind_X_corr.copy()
                                st.write("â—‹ è·³è¿‡å½’ä¸€åŒ–")
                            
                            # 5. SNVå¤„ç†
                            if params.get('apply_snv', False):
                                blind_X_preprocessed = np.zeros_like(blind_X_norm)
                                for i, spectrum in enumerate(blind_X_norm):
                                    mean_val = np.mean(spectrum)
                                    std_val = np.std(spectrum)
                                    if std_val == 0:
                                        blind_X_preprocessed[i] = spectrum
                                    else:
                                        blind_X_preprocessed[i] = (spectrum - mean_val) / std_val
                                st.write("âœ“ æ ‡å‡†æ­£æ€å˜é‡å˜æ¢(SNV): å·²åº”ç”¨")
                            else:
                                blind_X_preprocessed = blind_X_norm
                                st.write("â—‹ æ ‡å‡†æ­£æ€å˜é‡å˜æ¢(SNV): æœªåº”ç”¨")
                            
                            # â­ å…³é”®ä¿®å¤ï¼šåº”ç”¨ç‰¹å¾é€‰æ‹© â­
                            if hasattr(st.session_state, 'feature_selected') and st.session_state.feature_selected:
                                if st.session_state.feature_selection_method != "ä¸è¿›è¡Œç‰¹å¾é€‰æ‹©":
                                    # åº”ç”¨è®­ç»ƒæ—¶çš„ç‰¹å¾é€‰æ‹©
                                    selected_indices = st.session_state.selected_features
                                    blind_X_final = blind_X_preprocessed[:, selected_indices]
                                    st.write(f"âœ“ åº”ç”¨ç‰¹å¾é€‰æ‹©: {st.session_state.feature_selection_method}")
                                    st.write(f"ç‰¹å¾æ•°é‡: {blind_X_preprocessed.shape[1]} â†’ {blind_X_final.shape[1]}")
                                else:
                                    blind_X_final = blind_X_preprocessed
                                    st.write("â—‹ æœªè¿›è¡Œç‰¹å¾é€‰æ‹©")
                            else:
                                blind_X_final = blind_X_preprocessed
                                st.write("â—‹ æœªè¿›è¡Œç‰¹å¾é€‰æ‹©")
                            
                            # ç¡®å®šæœŸæœ›çš„ç‰¹å¾æ•°é‡
                            if hasattr(st.session_state, 'feature_selected') and st.session_state.feature_selected:
                                expected_features = st.session_state.X_final.shape[1]
                                data_source = "ç‰¹å¾é€‰æ‹©å"
                            else:
                                expected_features = st.session_state.X_preprocessed.shape[1]
                                data_source = "é¢„å¤„ç†å"
                            
                            st.write(f"**{data_source}ç‰¹å¾æ•°é‡**: {blind_X_final.shape[1]}")
                            st.write(f"**æ¨¡å‹æœŸæœ›ç‰¹å¾æ•°é‡**: {expected_features}")
                            
                            if blind_X_final.shape[1] != expected_features:
                                st.error(f"ç‰¹å¾æ•°é‡ä¸åŒ¹é…ï¼ç›²æ ·: {blind_X_final.shape[1]}, æœŸæœ›: {expected_features}")
                                
                                if blind_X_final.shape[1] > expected_features:
                                    st.warning("ç›²æ ·ç‰¹å¾æ•°é‡è¿‡å¤šï¼Œå°†æˆªå–å‰é¢çš„ç‰¹å¾")
                                    blind_X_final = blind_X_final[:, :expected_features]
                                    st.info(f"å·²è°ƒæ•´ä¸º: {blind_X_final.shape[1]} ä¸ªç‰¹å¾")
                                else:
                                    st.error("ç›²æ ·ç‰¹å¾æ•°é‡ä¸è¶³ï¼Œæ— æ³•è‡ªåŠ¨è°ƒæ•´")
                                    st.error("å¯èƒ½çš„åŸå› ï¼š")
                                    st.error("1. ç›²æ ·æ•°æ®çš„æ³¢æ•°èŒƒå›´ä¸è®­ç»ƒæ•°æ®ä¸åŒ¹é…")
                                    st.error("2. é¢„å¤„ç†å‚æ•°è®¾ç½®ä¸åŒ")
                                    st.error("3. ç‰¹å¾é€‰æ‹©è¿‡ç¨‹æœ‰å·®å¼‚")
                                    return
                            
                            # åº”ç”¨æ ‡å‡†åŒ–ï¼ˆå¦‚æœéœ€è¦ï¼‰
                            if selected_model_key in st.session_state.detailed_results:
                                scaler = st.session_state.detailed_results[selected_model_key].get('scaler')
                                if scaler is not None:
                                    blind_X_final = scaler.transform(blind_X_final)
                                    st.write("âœ“ åº”ç”¨è®­ç»ƒæ—¶çš„æ ‡å‡†åŒ–å˜æ¢")
                            
                            # ä½¿ç”¨é€‰å®šçš„æ¨¡å‹è¿›è¡Œé¢„æµ‹
                            model = st.session_state.trained_models[selected_model_key]
                            predictions = model.predict(blind_X_final)
                            
                            # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
                            st.subheader("é¢„æµ‹ç»“æœ")

                            # 1. æ„å»ºç»“æœDataFrameï¼Œå¹¶ç¡®ä¿åˆ—çš„é¡ºåºæ­£ç¡®
                            result_df = pd.DataFrame()

                            # 2. ä»åŸå§‹ç›²æ ·æ•°æ®ä¸­æå–æ ‡è¯†åˆ— (ä¿ç•™åŸå§‹åˆ—å)
                            if blind_df.shape[1] >= 1:
                                result_df[blind_df.columns[0]] = blind_df.iloc[:, 0]
                            if blind_df.shape[1] >= 2:
                                result_df[blind_df.columns[1]] = blind_df.iloc[:, 1]

                            # 3. æ·»åŠ é¢„æµ‹ç»“æœ
                            if predictions.ndim == 1:
                                # å•ç›®æ ‡é¢„æµ‹
                                pred_col_name = st.session_state.selected_cols[0] if len(st.session_state.selected_cols) == 1 else 'é¢„æµ‹å€¼'
                                result_df[f'{pred_col_name}_é¢„æµ‹å€¼'] = predictions
                            else:
                                # å¤šç›®æ ‡é¢„æµ‹
                                for i, col in enumerate(st.session_state.selected_cols):
                                    result_df[f'{col}_é¢„æµ‹å€¼'] = predictions[:, i]

                            # 4. åœ¨æœ€å‰é¢æ’å…¥ä¸€ä¸ªä»1å¼€å§‹çš„æ ·æœ¬ç´¢å¼•ï¼Œæ–¹ä¾¿æŸ¥çœ‹
                            result_df.insert(0, 'æ ·æœ¬ç´¢å¼•', np.arange(1, len(predictions) + 1))

                            # 5. æ˜¾ç¤ºæœ€ç»ˆçš„DataFrame
                            st.dataframe(result_df, use_container_width=True)
                            
                            # å¯è§†åŒ–é¢„æµ‹ç»“æœ
                            if predictions.ndim == 1:
                                fig, ax = plt.subplots(figsize=(10, 6))
                                ax.plot(result_df['æ ·æœ¬ç´¢å¼•'], predictions, 'o-', color='blue', markersize=6)
                                ax.set_title('ç›²æ ·é¢„æµ‹ç»“æœ')
                                ax.set_xlabel('æ ·æœ¬ç´¢å¼•')
                                ax.set_ylabel('é¢„æµ‹å€¼')
                                ax.grid(True, linestyle='--', alpha=0.7)
                                plt.tight_layout()
                                st.pyplot(fig)
                            
                            # æ˜¾ç¤ºé¢„å¤„ç†åçš„å…‰è°±
                            if st.checkbox("æŸ¥çœ‹é¢„å¤„ç†åçš„ç›²æ ·å…‰è°±"):
                                fig, ax = plt.subplots(figsize=(12, 6))
                                n_samples = min(10, blind_X_final.shape[0])
                                
                                # ç¡®å®šæ³¢æ•°
                                if hasattr(st.session_state, 'feature_selected') and st.session_state.feature_selected:
                                    if st.session_state.feature_selection_method != "ä¸è¿›è¡Œç‰¹å¾é€‰æ‹©":
                                        display_wavenumbers = st.session_state.wavenumbers_final
                                    else:
                                        display_wavenumbers = blind_wavenumbers_crop
                                else:
                                    display_wavenumbers = blind_wavenumbers_crop
                                
                                for i in range(n_samples):
                                    ax.plot(display_wavenumbers, blind_X_final[i], alpha=0.7)
                                ax.set_title(f'é¢„å¤„ç†åçš„ç›²æ ·å…‰è°± (æ˜¾ç¤ºå‰{n_samples}ä¸ªæ ·æœ¬)')
                                ax.set_xlabel('æ³¢æ•° (cmâ»Â¹)')
                                ax.set_ylabel('å¤„ç†åå¼ºåº¦')
                                ax.grid(True, linestyle='--', alpha=0.7)
                                plt.tight_layout()
                                st.pyplot(fig)
                            
                            # æä¾›ä¸‹è½½é“¾æ¥
                            csv = result_df.to_csv(index=False, encoding='utf-8-sig')
                            b64 = base64.b64encode(csv.encode('utf-8')).decode()
                            href = f'<a href="data:file/csv;base64,{b64}" download="ç›²æ ·é¢„æµ‹ç»“æœ.csv">ğŸ“¥ ä¸‹è½½é¢„æµ‹ç»“æœ</a>'
                            st.markdown(href, unsafe_allow_html=True)
                            
                            st.success("é¢„æµ‹å®Œæˆï¼")
                            
                        except Exception as e:
                            st.error(f"é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
                            st.error(traceback.format_exc())
                            
            except Exception as e:
                st.error(f"å¤„ç†ç›²æ ·æ•°æ®æ—¶å‡ºé”™: {e}")
                st.error(traceback.format_exc())
                
        except Exception as e:
            st.error(f"è¯»å–ç›²æ ·æ•°æ®å‡ºé”™: {e}")
            st.error(traceback.format_exc())
    else:
        st.info("è¯·ä¸Šä¼ ç›²æ ·æ•°æ®æ–‡ä»¶è¿›è¡Œé¢„æµ‹")
        
        # æ˜¾ç¤ºä½¿ç”¨è¯´æ˜
        st.subheader("ä½¿ç”¨è¯´æ˜")
        st.markdown("""
        **ç›²æ ·æ•°æ®æ ¼å¼è¦æ±‚ï¼š**
        1. æ”¯æŒCSVã€Excelæ ¼å¼
        2. æ•°æ®æ ¼å¼åº”ä¸è®­ç»ƒæ•°æ®ä¿æŒä¸€è‡´
        3. å‰ä¸¤åˆ—é€šå¸¸ä¸ºæ ·æœ¬æ ‡è¯†ä¿¡æ¯
        4. ç¬¬ä¸‰åˆ—å¼€å§‹ä¸ºæ³¢æ•°å¯¹åº”çš„å¼ºåº¦å€¼
        5. æ³¢æ•°èŒƒå›´åº”åŒ…å«è®­ç»ƒæ•°æ®çš„æ³¢æ•°èŒƒå›´
        
        **é¢„å¤„ç†æµç¨‹ï¼š**
        - ç³»ç»Ÿä¼šè‡ªåŠ¨åº”ç”¨ä¸è®­ç»ƒæ•°æ®ç›¸åŒçš„é¢„å¤„ç†æ­¥éª¤
        - åŒ…æ‹¬æ³¢æ•°æˆªå–ã€å¹³æ»‘ã€åŸºçº¿æ ¡æ­£ã€å½’ä¸€åŒ–ç­‰
        - **ç‰¹å¾é€‰æ‹©**ï¼šå¦‚æœè®­ç»ƒæ—¶è¿›è¡Œäº†ç‰¹å¾é€‰æ‹©ï¼Œä¼šè‡ªåŠ¨åº”ç”¨ç›¸åŒçš„ç‰¹å¾é€‰æ‹©
        - ç¡®ä¿ç‰¹å¾æ•°é‡ä¸è®­ç»ƒæ¨¡å‹åŒ¹é…
        
        **æ³¨æ„äº‹é¡¹ï¼š**
        - ç›²æ ·æ•°æ®çš„æ³¢æ•°èŒƒå›´åº”è¦†ç›–è®­ç»ƒæ•°æ®çš„æ³¢æ•°èŒƒå›´
        - å…‰è°±æ•°æ®çš„ä»ªå™¨æ¡ä»¶åº”ä¸è®­ç»ƒæ•°æ®ä¸€è‡´
        - é¢„æµ‹ç»“æœçš„å¯é æ€§å–å†³äºç›²æ ·ä¸è®­ç»ƒæ•°æ®çš„ç›¸ä¼¼æ€§
        - å¦‚æœè®­ç»ƒæ—¶è¿›è¡Œäº†ç‰¹å¾é€‰æ‹©ï¼Œç›²æ ·é¢„æµ‹ä¼šè‡ªåŠ¨åº”ç”¨ç›¸åŒçš„ç‰¹å¾é€‰æ‹©æ­¥éª¤
        """)


# ====================================
# 5. ä¸»å‡½æ•°
# ====================================

def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®é¡µé¢é…ç½®
    st.set_page_config(
        page_title="å’¸æ•°å…‰è°±æ•°æ®åˆ†æä¸é¢„æµ‹",
        page_icon="ğŸ”¬",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # è®¾ç½®é¡µé¢æ ·å¼
    set_page_style()
    
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    init_session_state()
    
    # ä¾§è¾¹æ å¯¼èˆª
    st.sidebar.title("ğŸ”¬ å’¸æ•°å…‰è°±æ•°æ®åˆ†æä¸é¢„æµ‹")
    st.sidebar.markdown("---")
    
    pages = {
        "1. æ•°æ®åŠ è½½ä¸æ ‡ç­¾è¾“å…¥": show_data_loading_page,
        "2. æ•°æ®é¢„å¤„ç†": show_preprocessing_page,
        "3. ç‰¹å¾æå–ä¸å¯è§†åŒ–": show_feature_extraction_page,
        "4. æ•°æ®é›†åˆ’åˆ†": show_data_split_page,
        "5. æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°": show_model_training_page,
        "6. ç›²æ ·é¢„æµ‹": show_blind_prediction_page
    }
    
    # é¡µé¢é€‰æ‹©
    selection = st.sidebar.radio("å¯¼èˆª", list(pages.keys()))
    
    # æ˜¾ç¤ºæ•°æ®åŠ è½½çŠ¶æ€
    st.sidebar.markdown("---")
    if hasattr(st.session_state, 'data_loaded') and st.session_state.data_loaded:
        st.sidebar.success("âœ… æ•°æ®å·²åŠ è½½")
        if hasattr(st.session_state, 'X') and hasattr(st.session_state, 'y'):
            st.sidebar.write(f"ğŸ“Š å…‰è°±æ•°æ®: {st.session_state.X.shape}")
            st.sidebar.write(f"ğŸ·ï¸ æ ‡ç­¾æ•°æ®: {st.session_state.y.shape}")
            st.sidebar.write(f"ğŸ¯ ç›®æ ‡å˜é‡: {', '.join(st.session_state.selected_cols)}")
    else:
        st.sidebar.warning("âš ï¸ è¯·å…ˆåŠ è½½æ•°æ®å’Œè®¾ç½®æ ‡ç­¾")
    
    # æ˜¾ç¤ºé¢„å¤„ç†çŠ¶æ€
    if hasattr(st.session_state, 'preprocessing_done') and st.session_state.preprocessing_done:
        st.sidebar.success("âœ… æ•°æ®é¢„å¤„ç†å®Œæˆ")
    
    # æ˜¾ç¤ºæ¨¡å‹è®­ç»ƒçŠ¶æ€
    if hasattr(st.session_state, 'trained_models') and st.session_state.trained_models:
        st.sidebar.success(f"âœ… å·²è®­ç»ƒ {len(st.session_state.trained_models)} ä¸ªæ¨¡å‹")
    
    # æ˜¾ç¤ºä½œè€…ä¿¡æ¯
    st.sidebar.markdown("---")
    st.sidebar.info(
        """
        **å’¸æ•°å…‰è°±æ•°æ®åˆ†æä¸é¢„æµ‹åº”ç”¨ v2.0**
        
        ä¸€ä¸ªç‹å†›ç”¨äºåˆ†æå…‰è°±æ•°æ®å¹¶æ„å»ºé¢„æµ‹æ¨¡å‹çš„ä¸“ä¸šåº”ç”¨ç¨‹åºã€‚
        
        **ä¸»è¦åŠŸèƒ½**ï¼š
        - ğŸ”„ çµæ´»çš„æ ‡ç­¾è¾“å…¥æ–¹å¼
        - ğŸ› ï¸ å®Œæ•´çš„æ•°æ®é¢„å¤„ç†æµç¨‹
        - ğŸ¤– å¤šç§æœºå™¨å­¦ä¹ ç®—æ³•
        - ğŸ“Š æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°
        - ğŸ”® ç›²æ ·é¢„æµ‹åŠŸèƒ½
        
        **åŸºçº¿æ ¡æ­£ç®—æ³•**ï¼š
        - AIRPLS (è‡ªé€‚åº”è¿­ä»£åŠ æƒæƒ©ç½šæœ€å°äºŒä¹˜)
        - ASLS (éå¯¹ç§°æœ€å°äºŒä¹˜)
        - Polynomial (å¤šé¡¹å¼æ‹Ÿåˆ)
        - ModPoly (ä¿®æ­£å¤šé¡¹å¼)
        
        **æ”¯æŒçš„æ¨¡å‹**ï¼š
        çº¿æ€§å›å½’ã€å²­å›å½’ã€Lassoã€SVRã€éšæœºæ£®æ—ã€æ¢¯åº¦æå‡ã€MLPã€PLSã€XGBoost
        """
    )
    
    # æ˜¾ç¤ºé€‰å®šçš„é¡µé¢
    page_func = pages[selection]
    page_func()

# ====================================
# 6. ç¨‹åºå…¥å£
# ====================================

if __name__ == "__main__":
    main()